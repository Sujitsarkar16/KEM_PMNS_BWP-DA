{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from scipy import stats as scipy_stats\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 4: SIMPLIFIED EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"Deep Dive into Data Patterns and Relationships\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_processed_data():\n",
        "    \"\"\"Load the processed dataset with engineered features\"\"\"\n",
        "    print(\"\\n📊 STEP 1: LOADING PROCESSED DATA\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    try:\n",
        "        # Load the cleaned dataset\n",
        "        df = pd.read_excel('Data/processed/cleaned_dataset_with_engineered_features.xlsx')\n",
        "        print(\"✅ Processed dataset loaded successfully!\")\n",
        "        \n",
        "        # Load variable grouping table\n",
        "        grouping_df = pd.read_csv('Data/processed/variable_grouping_table.csv')\n",
        "        print(\"✅ Variable grouping table loaded successfully!\")\n",
        "        \n",
        "        print(f\"📏 Dataset shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "        \n",
        "        return df, grouping_df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading processed data: {e}\")\n",
        "        return None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_domain_variables(df, grouping_df, domain_name):\n",
        "    \"\"\"Analyze variables in a specific domain\"\"\"\n",
        "    print(f\"\\n📊 ANALYZING {domain_name.upper()} VARIABLES\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Get variables in this domain\n",
        "    domain_vars = grouping_df[grouping_df['Domain'] == domain_name]['Variable'].tolist()\n",
        "    domain_vars = [var for var in domain_vars if var in df.columns]\n",
        "    \n",
        "    print(f\"📊 {domain_name} variables: {len(domain_vars)}\")\n",
        "    if domain_vars:\n",
        "        print(f\"Variables: {domain_vars[:10]}{'...' if len(domain_vars) > 10 else ''}\")\n",
        "    \n",
        "    if not domain_vars:\n",
        "        print(f\"⚠️  No {domain_name} variables found\")\n",
        "        return {}\n",
        "    \n",
        "    # Analyze each variable\n",
        "    domain_analysis = {}\n",
        "    \n",
        "    for var in domain_vars:\n",
        "        if df[var].dtype in ['int64', 'float64']:\n",
        "            # Continuous variable analysis\n",
        "            stats_dict = {\n",
        "                'mean': df[var].mean(),\n",
        "                'std': df[var].std(),\n",
        "                'min': df[var].min(),\n",
        "                'max': df[var].max(),\n",
        "                'median': df[var].median(),\n",
        "                'missing': df[var].isnull().sum(),\n",
        "                'unique_values': df[var].nunique()\n",
        "            }\n",
        "        else:\n",
        "            # Categorical variable analysis\n",
        "            value_counts = df[var].value_counts()\n",
        "            stats_dict = {\n",
        "                'value_counts': value_counts.to_dict(),\n",
        "                'missing': df[var].isnull().sum(),\n",
        "                'unique_values': df[var].nunique(),\n",
        "                'most_common': value_counts.index[0] if len(value_counts) > 0 else None\n",
        "            }\n",
        "        \n",
        "        domain_analysis[var] = stats_dict\n",
        "    \n",
        "    # Display summary\n",
        "    print(f\"\\n📈 {domain_name} Summary:\")\n",
        "    for var, stats in list(domain_analysis.items())[:5]:  # Show first 5\n",
        "        print(f\"\\n  {var}:\")\n",
        "        if 'mean' in stats:\n",
        "            print(f\"    Mean: {stats['mean']:.2f}, Std: {stats['std']:.2f}\")\n",
        "            print(f\"    Range: {stats['min']:.2f} - {stats['max']:.2f}\")\n",
        "        else:\n",
        "            print(f\"    Unique values: {stats['unique_values']}\")\n",
        "            print(f\"    Most common: {stats['most_common']}\")\n",
        "    \n",
        "    if len(domain_analysis) > 5:\n",
        "        print(f\"\\n  ... and {len(domain_analysis) - 5} more variables\")\n",
        "    \n",
        "    return domain_analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correlation_analysis_with_birthweight(df):\n",
        "    \"\"\"Perform correlation analysis with birthweight\"\"\"\n",
        "    print(\"\\n📊 STEP 2: CORRELATION ANALYSIS WITH BIRTHWEIGHT\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    if 'f1_bw' not in df.columns:\n",
        "        print(\"❌ f1_bw variable not found\")\n",
        "        return {}\n",
        "    \n",
        "    # Get numerical variables\n",
        "    numerical_vars = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    \n",
        "    # Remove constant columns and birthweight itself\n",
        "    numerical_vars = [var for var in numerical_vars if df[var].nunique() > 1 and var != 'f1_bw']\n",
        "    \n",
        "    print(f\"📊 Analyzing correlations with {len(numerical_vars)} numerical variables\")\n",
        "    \n",
        "    # Calculate correlations with birthweight\n",
        "    correlations = {}\n",
        "    for var in numerical_vars[:100]:  # Limit to first 100 variables for performance\n",
        "        if var in df.columns:\n",
        "            try:\n",
        "                # Get common non-null values\n",
        "                common_idx = df[var].dropna().index.intersection(df['f1_bw'].dropna().index)\n",
        "                if len(common_idx) > 10:  # Need at least 10 observations\n",
        "                    corr_coef, p_value = scipy_stats.pearsonr(df.loc[common_idx, var], df.loc[common_idx, 'f1_bw'])\n",
        "                    correlations[var] = {\n",
        "                        'correlation': corr_coef,\n",
        "                        'p_value': p_value,\n",
        "                        'abs_correlation': abs(corr_coef)\n",
        "                    }\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    # Sort by absolute correlation\n",
        "    sorted_correlations = sorted(correlations.items(), key=lambda x: x[1]['abs_correlation'], reverse=True)\n",
        "    \n",
        "    # Display top correlations\n",
        "    print(\"\\n📈 Top 20 Correlations with Birthweight:\")\n",
        "    print(\"Variable\".ljust(30) + \"Correlation\".ljust(15) + \"P-value\".ljust(15) + \"Significance\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    for var, stats in sorted_correlations[:20]:\n",
        "        significance = \"***\" if stats['p_value'] < 0.001 else \"**\" if stats['p_value'] < 0.01 else \"*\" if stats['p_value'] < 0.05 else \"\"\n",
        "        print(f\"{var[:29].ljust(30)}{stats['correlation']:8.4f}     {stats['p_value']:8.4f}     {significance}\")\n",
        "    \n",
        "    return correlations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def risk_factor_analysis(df):\n",
        "    \"\"\"Identify key risk factors for low birthweight\"\"\"\n",
        "    print(\"\\n📊 STEP 3: RISK FACTOR ANALYSIS FOR LOW BIRTHWEIGHT\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    if 'LBW_flag' not in df.columns:\n",
        "        print(\"❌ LBW_flag not found in dataset\")\n",
        "        return {}\n",
        "    \n",
        "    # Get numerical variables for analysis\n",
        "    numerical_vars = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numerical_vars = [var for var in numerical_vars if var not in ['LBW_flag', 'f1_bw'] and df[var].nunique() > 1]\n",
        "    \n",
        "    print(f\"📊 Analyzing {len(numerical_vars)} variables for LBW risk factors\")\n",
        "    \n",
        "    risk_factors = {}\n",
        "    \n",
        "    for var in numerical_vars[:50]:  # Limit to first 50 variables for performance\n",
        "        if var in df.columns:\n",
        "            try:\n",
        "                # Compare means between LBW and normal birthweight groups\n",
        "                lbw_group = df[df['LBW_flag'] == 1][var].dropna()\n",
        "                normal_group = df[df['LBW_flag'] == 0][var].dropna()\n",
        "                \n",
        "                if len(lbw_group) > 5 and len(normal_group) > 5:\n",
        "                    # T-test\n",
        "                    t_stat, p_value = scipy_stats.ttest_ind(lbw_group, normal_group)\n",
        "                    \n",
        "                    # Effect size (Cohen's d)\n",
        "                    pooled_std = np.sqrt(((len(lbw_group) - 1) * lbw_group.std()**2 + \n",
        "                                        (len(normal_group) - 1) * normal_group.std()**2) / \n",
        "                                       (len(lbw_group) + len(normal_group) - 2))\n",
        "                    cohens_d = (lbw_group.mean() - normal_group.mean()) / pooled_std\n",
        "                    \n",
        "                    risk_factors[var] = {\n",
        "                        'lbw_mean': lbw_group.mean(),\n",
        "                        'normal_mean': normal_group.mean(),\n",
        "                        'difference': lbw_group.mean() - normal_group.mean(),\n",
        "                        't_statistic': t_stat,\n",
        "                        'p_value': p_value,\n",
        "                        'cohens_d': cohens_d,\n",
        "                        'effect_size': 'large' if abs(cohens_d) > 0.8 else 'medium' if abs(cohens_d) > 0.5 else 'small'\n",
        "                    }\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    # Sort by p-value\n",
        "    sorted_risk_factors = sorted(risk_factors.items(), key=lambda x: x[1]['p_value'])\n",
        "    \n",
        "    # Display significant risk factors\n",
        "    print(\"\\n📈 Significant Risk Factors for Low Birthweight (p < 0.05):\")\n",
        "    print(\"Variable\".ljust(30) + \"LBW Mean\".ljust(12) + \"Normal Mean\".ljust(12) + \"Difference\".ljust(12) + \"P-value\".ljust(12) + \"Effect Size\")\n",
        "    print(\"-\" * 90)\n",
        "    \n",
        "    significant_factors = 0\n",
        "    for var, stats in sorted_risk_factors:\n",
        "        if stats['p_value'] < 0.05:\n",
        "            significant_factors += 1\n",
        "            print(f\"{var[:29].ljust(30)}{stats['lbw_mean']:8.2f}    {stats['normal_mean']:8.2f}    {stats['difference']:8.2f}    {stats['p_value']:8.4f}    {stats['effect_size']}\")\n",
        "    \n",
        "    print(f\"\\n📊 Found {significant_factors} significant risk factors\")\n",
        "    \n",
        "    return risk_factors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_eda_plots(df, grouping_df):\n",
        "    \"\"\"Create EDA visualization plots\"\"\"\n",
        "    print(\"\\n📊 STEP 4: CREATING EDA PLOTS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Create plots directory\n",
        "    plots_dir = Path('PLOTS')\n",
        "    plots_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # 1. Birthweight distribution by sex\n",
        "    print(\"📊 Creating birthweight distribution plots...\")\n",
        "    \n",
        "    if 'f1_sex' in df.columns and 'f1_bw' in df.columns:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        \n",
        "        # Subplot 1: Overall distribution\n",
        "        plt.subplot(2, 3, 1)\n",
        "        plt.hist(df['f1_bw'], bins=30, alpha=0.7, edgecolor='black', color='skyblue')\n",
        "        plt.axvline(2500, color='red', linestyle='--', label='LBW threshold (2500g)')\n",
        "        plt.xlabel('Birthweight (grams)')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title('Overall Birthweight Distribution')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Subplot 2: By sex\n",
        "        plt.subplot(2, 3, 2)\n",
        "        sex_1_data = df[df['f1_sex'] == 1]['f1_bw'].dropna()\n",
        "        sex_2_data = df[df['f1_sex'] == 2]['f1_bw'].dropna()\n",
        "        plt.hist([sex_1_data, sex_2_data], bins=20, alpha=0.7, label=['Sex 1', 'Sex 2'], \n",
        "                color=['blue', 'pink'], edgecolor='black')\n",
        "        plt.xlabel('Birthweight (grams)')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title('Birthweight Distribution by Sex')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Subplot 3: LBW flag distribution\n",
        "        plt.subplot(2, 3, 3)\n",
        "        lbw_counts = df['LBW_flag'].value_counts()\n",
        "        plt.pie(lbw_counts.values, labels=['Normal BW', 'LBW'], autopct='%1.1f%%', startangle=90)\n",
        "        plt.title('Low Birthweight Distribution')\n",
        "        \n",
        "        # Subplot 4: Box plot by sex\n",
        "        plt.subplot(2, 3, 4)\n",
        "        df.boxplot(column='f1_bw', by='f1_sex', ax=plt.gca())\n",
        "        plt.title('Birthweight by Sex')\n",
        "        plt.suptitle('')  # Remove automatic title\n",
        "        \n",
        "        # Subplot 5: LBW rate by sex\n",
        "        plt.subplot(2, 3, 5)\n",
        "        lbw_by_sex = df.groupby('f1_sex')['LBW_flag'].mean() * 100\n",
        "        bars = plt.bar(['Sex 1', 'Sex 2'], lbw_by_sex.values, color=['blue', 'pink'], edgecolor='black')\n",
        "        plt.ylabel('LBW Rate (%)')\n",
        "        plt.title('LBW Rate by Sex')\n",
        "        for bar, rate in zip(bars, lbw_by_sex.values):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
        "                    f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Subplot 6: Maternal age vs birthweight\n",
        "        plt.subplot(2, 3, 6)\n",
        "        if 'f0_m_age' in df.columns:\n",
        "            plt.scatter(df['f0_m_age'], df['f1_bw'], alpha=0.6, s=20)\n",
        "            plt.xlabel('Maternal Age (years)')\n",
        "            plt.ylabel('Birthweight (grams)')\n",
        "            plt.title('Maternal Age vs Birthweight')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(plots_dir / 'comprehensive_birthweight_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"✅ Birthweight analysis plots saved\")\n",
        "    \n",
        "    # 2. Domain distribution plot\n",
        "    print(\"📊 Creating domain distribution plot...\")\n",
        "    \n",
        "    domain_counts = grouping_df['Domain'].value_counts()\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    bars = plt.bar(range(len(domain_counts)), domain_counts.values, color='lightcoral', edgecolor='black')\n",
        "    plt.xlabel('Domain')\n",
        "    plt.ylabel('Number of Variables')\n",
        "    plt.title('Variable Distribution by Domain')\n",
        "    plt.xticks(range(len(domain_counts)), domain_counts.index, rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, count in zip(bars, domain_counts.values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
        "                str(count), ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(plots_dir / 'domain_distribution_eda.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"✅ Domain distribution plot saved\")\n",
        "    \n",
        "    # 3. Key variable correlations\n",
        "    print(\"📊 Creating correlation heatmap...\")\n",
        "    \n",
        "    # Get key variables for correlation\n",
        "    key_vars = []\n",
        "    for domain in ['Maternal_socio_demographic', 'Maternal_clinical_biomarkers', 'Maternal_anthropometry']:\n",
        "        domain_vars = grouping_df[grouping_df['Domain'] == domain]['Variable'].tolist()\n",
        "        domain_vars = [var for var in domain_vars if var in df.columns and df[var].dtype in ['int64', 'float64'] and df[var].nunique() > 1]\n",
        "        key_vars.extend(domain_vars[:5])  # Take first 5 from each domain\n",
        "    \n",
        "    # Add birthweight\n",
        "    if 'f1_bw' in df.columns:\n",
        "        key_vars.append('f1_bw')\n",
        "    \n",
        "    # Limit to 20 variables for readability\n",
        "    key_vars = key_vars[:20]\n",
        "    \n",
        "    if len(key_vars) > 1:\n",
        "        plt.figure(figsize=(15, 12))\n",
        "        correlation_matrix = df[key_vars].corr()\n",
        "        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "                   square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "        plt.title('Correlation Heatmap - Key Variables', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(plots_dir / 'key_variables_correlation.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(\"✅ Correlation heatmap saved\")\n",
        "    \n",
        "    print(f\"✅ All EDA plots saved to {plots_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_eda_summary_report(df, grouping_df, correlations, risk_factors):\n",
        "    \"\"\"Create EDA summary report\"\"\"\n",
        "    print(\"\\n📊 STEP 5: CREATING EDA SUMMARY REPORT\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Create reports directory\n",
        "    reports_dir = Path('Reports')\n",
        "    reports_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Create summary statistics\n",
        "    summary_stats = []\n",
        "    \n",
        "    # Dataset overview\n",
        "    summary_stats.append({\n",
        "        'Category': 'Dataset Overview',\n",
        "        'Metric': 'Total Variables',\n",
        "        'Value': df.shape[1],\n",
        "        'Description': 'Total number of variables in the dataset'\n",
        "    })\n",
        "    \n",
        "    summary_stats.append({\n",
        "        'Category': 'Dataset Overview',\n",
        "        'Metric': 'Total Observations',\n",
        "        'Value': df.shape[0],\n",
        "        'Description': 'Total number of observations'\n",
        "    })\n",
        "    \n",
        "    summary_stats.append({\n",
        "        'Category': 'Dataset Overview',\n",
        "        'Metric': 'Missing Values',\n",
        "        'Value': df.isnull().sum().sum(),\n",
        "        'Description': 'Total missing values across all variables'\n",
        "    })\n",
        "    \n",
        "    # Birthweight analysis\n",
        "    if 'f1_bw' in df.columns:\n",
        "        summary_stats.append({\n",
        "            'Category': 'Birthweight Analysis',\n",
        "            'Metric': 'Mean Birthweight (g)',\n",
        "            'Value': round(df['f1_bw'].mean(), 2),\n",
        "            'Description': 'Average birthweight in grams'\n",
        "        })\n",
        "        \n",
        "        summary_stats.append({\n",
        "            'Category': 'Birthweight Analysis',\n",
        "            'Metric': 'LBW Rate (%)',\n",
        "            'Value': round((df['LBW_flag'].sum() / len(df)) * 100, 2),\n",
        "            'Description': 'Percentage of low birthweight cases'\n",
        "        })\n",
        "    \n",
        "    # Domain analysis\n",
        "    domain_counts = grouping_df['Domain'].value_counts()\n",
        "    for domain, count in domain_counts.items():\n",
        "        summary_stats.append({\n",
        "            'Category': 'Domain Analysis',\n",
        "            'Metric': f'{domain} Variables',\n",
        "            'Value': count,\n",
        "            'Description': f'Number of variables in {domain} domain'\n",
        "        })\n",
        "    \n",
        "    # Correlation analysis\n",
        "    significant_correlations = [var for var, stats in correlations.items() if abs(stats['correlation']) > 0.3]\n",
        "    summary_stats.append({\n",
        "        'Category': 'Correlation Analysis',\n",
        "        'Metric': 'Strong Correlations (>0.3)',\n",
        "        'Value': len(significant_correlations),\n",
        "        'Description': 'Variables with strong correlation to birthweight'\n",
        "    })\n",
        "    \n",
        "    # Risk factor analysis\n",
        "    significant_risk_factors = [var for var, stats in risk_factors.items() if stats['p_value'] < 0.05]\n",
        "    summary_stats.append({\n",
        "        'Category': 'Risk Factor Analysis',\n",
        "        'Metric': 'Significant Risk Factors',\n",
        "        'Value': len(significant_risk_factors),\n",
        "        'Description': 'Variables significantly associated with LBW'\n",
        "    })\n",
        "    \n",
        "    # Create DataFrame and save\n",
        "    summary_df = pd.DataFrame(summary_stats)\n",
        "    report_file = reports_dir / 'eda_summary_report.csv'\n",
        "    summary_df.to_csv(report_file, index=False)\n",
        "    \n",
        "    print(f\"✅ EDA summary report saved: {report_file}\")\n",
        "    \n",
        "    # Display summary\n",
        "    print(\"\\n📈 EDA Summary Report:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "    \n",
        "    return report_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    # Load processed data\n",
        "    df, grouping_df = load_processed_data()\n",
        "    if df is None:\n",
        "        return\n",
        "    \n",
        "    # Analyze each domain\n",
        "    domains = ['Maternal_socio_demographic', 'Maternal_clinical_biomarkers', \n",
        "              'Maternal_anthropometry', 'Household_environment', 'Child_outcomes']\n",
        "    \n",
        "    domain_analyses = {}\n",
        "    for domain in domains:\n",
        "        domain_analyses[domain] = analyze_domain_variables(df, grouping_df, domain)\n",
        "    \n",
        "    # Correlation and risk factor analysis\n",
        "    correlations = correlation_analysis_with_birthweight(df)\n",
        "    risk_factors = risk_factor_analysis(df)\n",
        "    \n",
        "    # Create visualizations\n",
        "    create_eda_plots(df, grouping_df)\n",
        "    \n",
        "    # Create summary report\n",
        "    report_file = create_eda_summary_report(df, grouping_df, correlations, risk_factors)\n",
        "    \n",
        "    # Final summary\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SIMPLIFIED EDA COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"✅ Analysis completed:\")\n",
        "    print(\"  - Domain-wise variable analysis\")\n",
        "    print(\"  - Correlation analysis with birthweight\")\n",
        "    print(\"  - Risk factor analysis for LBW\")\n",
        "    print(\"  - Comprehensive visualizations created\")\n",
        "    print(\"  - EDA summary report generated\")\n",
        "    print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
