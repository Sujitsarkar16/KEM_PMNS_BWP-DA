{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "language": "python"
  },
  "cells": [
    {
      "id": "dfa7ee84",
      "cell_type": "markdown",
      "source": "# Comprehensive EDA Visualization Notebook\n\nThis notebook was converted from `01_create_plots.py`.\n\n- The original script's logic and code lines were preserved; only split into logical notebook cells for interactivity.\n- Run cells in order. Outputs (plots) will be displayed inline and saved to PNG files as in the original script.\n",
      "metadata": {}
    },
    {
      "id": "2714f72b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set style for better visualizations\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\nprint(\"Creating comprehensive visualizations for EDA analysis...\")\n",
      "outputs": []
    },
    {
      "id": "b86211b0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Load the dataset\ndf = pd.read_excel('IMPUTED_DATA_WITH REDUCED_columns_21_09_2025.xlsx')\ndf = df.drop('Unnamed: 0', axis=1)\n",
      "outputs": []
    },
    {
      "id": "93e4d5b1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Create a comprehensive visualization report\nfig = plt.figure(figsize=(20, 24))\n\n# 1. Dataset Overview\nax1 = plt.subplot(4, 3, 1)\nax1.text(0.5, 0.7, f'Dataset Overview', ha='center', va='center', fontsize=16, fontweight='bold')\nax1.text(0.5, 0.5, f'Rows: {df.shape[0]:,}', ha='center', va='center', fontsize=14)\nax1.text(0.5, 0.4, f'Columns: {df.shape[1]:,}', ha='center', va='center', fontsize=14)\nax1.text(0.5, 0.3, f'Missing Values: 0', ha='center', va='center', fontsize=14, color='green')\nax1.text(0.5, 0.2, f'Data Types: All Numerical', ha='center', va='center', fontsize=14)\nax1.set_xlim(0, 1)\nax1.set_ylim(0, 1)\nax1.axis('off')\n\n# 2. Variable Distribution by Type\nax2 = plt.subplot(4, 3, 2)\nvariable_types = {\n    'Demographics': 7,\n    'Anthropometric': 25,\n    'Biochemical': 18,\n    'Dietary': 130,\n    'Outcomes': 6,\n    'Other': df.shape[1] - 186\n}\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']\nwedges, texts, autotexts = ax2.pie(variable_types.values(), labels=variable_types.keys(), \n                                  autopct='%1.1f%%', colors=colors, startangle=90)\nax2.set_title('Variable Distribution by Type', fontsize=14, fontweight='bold')\n\n# 3. Key Variables Analysis - Birth Weight Distribution\nax3 = plt.subplot(4, 3, 3)\nif 'f1_bw' in df.columns:\n    ax3.hist(df['f1_bw'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n    ax3.axvline(df['f1_bw'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"f1_bw\"].mean():.0f}g')\n    ax3.axvline(df['f1_bw'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[\"f1_bw\"].median():.0f}g')\n    ax3.set_xlabel('Birth Weight (g)')\n    ax3.set_ylabel('Frequency')\n    ax3.set_title('Birth Weight Distribution', fontsize=14, fontweight='bold')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n\n# 4. Maternal Age Distribution\nax4 = plt.subplot(4, 3, 4)\nif 'f0_m_age' in df.columns:\n    ax4.hist(df['f0_m_age'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n    ax4.axvline(df['f0_m_age'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"f0_m_age\"].mean():.1f}')\n    ax4.set_xlabel('Maternal Age (years)')\n    ax4.set_ylabel('Frequency')\n    ax4.set_title('Maternal Age Distribution', fontsize=14, fontweight='bold')\n    ax4.legend()\n    ax4.grid(True, alpha=0.3)\n\n# 5. Maternal BMI Distribution\nax5 = plt.subplot(4, 3, 5)\nif 'f0_m_bmi_prepreg' in df.columns:\n    ax5.hist(df['f0_m_bmi_prepreg'], bins=25, alpha=0.7, color='lightgreen', edgecolor='black')\n    ax5.axvline(df['f0_m_bmi_prepreg'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"f0_m_bmi_prepreg\"].mean():.1f}')\n    ax5.set_xlabel('Pre-pregnancy BMI (kg/m\u00b2)')\n    ax5.set_ylabel('Frequency')\n    ax5.set_title('Pre-pregnancy BMI Distribution', fontsize=14, fontweight='bold')\n    ax5.legend()\n    ax5.grid(True, alpha=0.3)\n\n# 6. Hemoglobin Levels (V1)\nax6 = plt.subplot(4, 3, 6)\nif 'f0_m_hb_v1' in df.columns:\n    ax6.hist(df['f0_m_hb_v1'], bins=25, alpha=0.7, color='gold', edgecolor='black')\n    ax6.axvline(df['f0_m_hb_v1'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"f0_m_hb_v1\"].mean():.1f}')\n    ax6.axvline(11, color='orange', linestyle='-', linewidth=2, label='Anemia threshold (11 g/dL)')\n    ax6.set_xlabel('Hemoglobin (g/dL)')\n    ax6.set_ylabel('Frequency')\n    ax6.set_title('Maternal Hemoglobin (Visit 1)', fontsize=14, fontweight='bold')\n    ax6.legend()\n    ax6.grid(True, alpha=0.3)\n\n# 7. Imputation Artifacts Analysis\nax7 = plt.subplot(4, 3, 7)\n# Analyze some key variables for imputation patterns\nvariables_to_check = ['f0_edu_hou_head', 'f1_sex', 'f0_occ_hou_head', 'f0_iron_well', 'f0_m_iron_tab_v1']\nimputation_scores = []\n\nfor var in variables_to_check:\n    if var in df.columns:\n        value_counts = df[var].value_counts()\n        max_freq_pct = (value_counts.iloc[0] / len(df)) * 100\n        imputation_scores.append(max_freq_pct)\n\nif imputation_scores:\n    bars = ax7.bar(range(len(variables_to_check)), imputation_scores, color='red', alpha=0.7)\n    ax7.set_xticks(range(len(variables_to_check)))\n    ax7.set_xticklabels([var.split('_')[-1] for var in variables_to_check], rotation=45)\n    ax7.set_ylabel('Max Value Frequency (%)')\n    ax7.set_title('Potential Imputation Artifacts\\n(High frequency of identical values)', fontsize=14, fontweight='bold')\n    ax7.axhline(y=20, color='orange', linestyle='--', linewidth=2, label='Suspicious threshold (20%)')\n    ax7.legend()\n    ax7.grid(True, alpha=0.3)\n\n# 8. Correlation Heatmap (subset of variables)\nax8 = plt.subplot(4, 3, 8)\n# Select a subset of key variables for correlation\nkey_vars = ['f0_m_age', 'f0_m_bmi_prepreg', 'f0_m_hb_v1', 'f0_m_hb_v2', 'f1_bw']\navailable_vars = [var for var in key_vars if var in df.columns]\n\nif len(available_vars) > 1:\n    corr_matrix = df[available_vars].corr()\n    im = ax8.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n    ax8.set_xticks(range(len(available_vars)))\n    ax8.set_yticks(range(len(available_vars)))\n    ax8.set_xticklabels([var.split('_')[-1] for var in available_vars], rotation=45)\n    ax8.set_yticklabels([var.split('_')[-1] for var in available_vars])\n    ax8.set_title('Correlation Matrix\\n(Key Variables)', fontsize=14, fontweight='bold')\n    \n    # Add correlation values to the heatmap\n    for i in range(len(available_vars)):\n        for j in range(len(available_vars)):\n            text = ax8.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n                           ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n    \n    plt.colorbar(im, ax=ax8, shrink=0.8)\n\n# 9. Data Quality Summary\nax9 = plt.subplot(4, 3, 9)\nquality_metrics = {\n    'Complete Cases': 100,\n    'Missing Values': 0,\n    'High Dimensionality': 100,  # 854 variables vs 791 observations\n    'Potential Imputation': 60   # Estimated based on analysis\n}\ncolors = ['green', 'green', 'red', 'orange']\nbars = ax9.bar(quality_metrics.keys(), quality_metrics.values(), color=colors, alpha=0.7)\nax9.set_ylabel('Score (%)')\nax9.set_title('Data Quality Assessment', fontsize=14, fontweight='bold')\nax9.set_ylim(0, 100)\nfor bar, value in zip(bars, quality_metrics.values()):\n    ax9.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n             f'{value}%', ha='center', va='bottom', fontweight='bold')\nax9.grid(True, alpha=0.3)\n\n# 10. Variable Importance (based on variance)\nax10 = plt.subplot(4, 3, 10)\n# Calculate variance for all variables\nvariances = df.var().sort_values(ascending=False)\ntop_10_vars = variances.head(10)\nbars = ax10.barh(range(len(top_10_vars)), top_10_vars.values, color='steelblue', alpha=0.7)\nax10.set_yticks(range(len(top_10_vars)))\nax10.set_yticklabels([var.split('_')[-1] for var in top_10_vars.index], fontsize=8)\nax10.set_xlabel('Variance')\nax10.set_title('Top 10 Variables by Variance', fontsize=14, fontweight='bold')\nax10.grid(True, alpha=0.3)\n\n# 11. Sample Size vs Variables\nax11 = plt.subplot(4, 3, 11)\nsample_sizes = [100, 200, 500, 791, 1000, 2000]\nrecommended_vars = [10, 20, 50, 100, 150, 200]\ncurrent_vars = [df.shape[1]] * len(sample_sizes)\n\nax11.plot(sample_sizes, recommended_vars, 'g-', linewidth=3, label='Recommended (10:1 ratio)', marker='o')\nax11.plot(sample_sizes, current_vars, 'r--', linewidth=3, label=f'Current Dataset ({df.shape[1]} vars)', marker='s')\nax11.axvline(791, color='blue', linestyle=':', alpha=0.7, label='Current Sample Size')\nax11.set_xlabel('Sample Size')\nax11.set_ylabel('Number of Variables')\nax11.set_title('Sample Size vs Variables\\n(Overfitting Risk)', fontsize=14, fontweight='bold')\nax11.legend()\nax11.grid(True, alpha=0.3)\n\n# 12. Recommendations Summary\nax12 = plt.subplot(4, 3, 12)\nax12.text(0.1, 0.9, 'CRITICAL RECOMMENDATIONS:', fontsize=14, fontweight='bold', color='red')\nax12.text(0.1, 0.8, '1. Dimensionality Reduction', fontsize=12, fontweight='bold')\nax12.text(0.1, 0.75, '   - Apply PCA or feature selection', fontsize=10)\nax12.text(0.1, 0.7, '   - Group related variables', fontsize=10)\nax12.text(0.1, 0.6, '2. Imputation Validation', fontsize=12, fontweight='bold')\nax12.text(0.1, 0.55, '   - Request pre-imputation data', fontsize=10)\nax12.text(0.1, 0.5, '   - Consider MICE/KNN methods', fontsize=10)\nax12.text(0.1, 0.4, '3. Modeling Strategy', fontsize=12, fontweight='bold')\nax12.text(0.1, 0.35, '   - Use regularization', fontsize=10)\nax12.text(0.1, 0.3, '   - Implement cross-validation', fontsize=10)\nax12.text(0.1, 0.2, '4. Validation Strategy', fontsize=12, fontweight='bold')\nax12.text(0.1, 0.15, '   - Proper train/test splits', fontsize=10)\nax12.text(0.1, 0.1, '   - Stratified sampling', fontsize=10)\nax12.set_xlim(0, 1)\nax12.set_ylim(0, 1)\nax12.axis('off')\n\nplt.tight_layout()\nplt.savefig('comprehensive_eda_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"\u2705 Comprehensive visualizations created and saved as 'comprehensive_eda_analysis.png'\")\n",
      "outputs": []
    },
    {
      "id": "b2413b12",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Create additional detailed plots for specific analysis\nprint(\"\\nCreating detailed imputation analysis plots...\")\n\n# Detailed imputation analysis\nfig2, axes = plt.subplots(2, 3, figsize=(18, 12))\n\n# Plot 1: Value frequency analysis for suspicious variables\nax1 = axes[0, 0]\nsuspicious_vars = ['f0_edu_hou_head', 'f1_sex', 'f0_occ_hou_head']\nfreq_data = []\nfor var in suspicious_vars:\n    if var in df.columns:\n        value_counts = df[var].value_counts()\n        max_freq = (value_counts.iloc[0] / len(df)) * 100\n        freq_data.append(max_freq)\n\nif freq_data:\n    bars = ax1.bar(suspicious_vars, freq_data, color=['red', 'orange', 'yellow'], alpha=0.7)\n    ax1.axhline(y=20, color='red', linestyle='--', linewidth=2, label='Suspicious threshold (20%)')\n    ax1.set_ylabel('Max Value Frequency (%)')\n    ax1.set_title('Imputation Artifacts Detection', fontweight='bold')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n\n# Plot 2: Distribution comparison for a key variable\nax2 = axes[0, 1]\nif 'f0_m_hb_v1' in df.columns:\n    ax2.hist(df['f0_m_hb_v1'], bins=30, alpha=0.7, color='skyblue', density=True, label='Hemoglobin V1')\n    if 'f0_m_hb_v2' in df.columns:\n        ax2.hist(df['f0_m_hb_v2'], bins=30, alpha=0.7, color='lightcoral', density=True, label='Hemoglobin V2')\n    ax2.set_xlabel('Hemoglobin (g/dL)')\n    ax2.set_ylabel('Density')\n    ax2.set_title('Hemoglobin Distribution Comparison', fontweight='bold')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n\n# Plot 3: Birth weight vs maternal BMI\nax3 = axes[0, 2]\nif 'f1_bw' in df.columns and 'f0_m_bmi_prepreg' in df.columns:\n    ax3.scatter(df['f0_m_bmi_prepreg'], df['f1_bw'], alpha=0.6, color='green')\n    ax3.set_xlabel('Pre-pregnancy BMI (kg/m\u00b2)')\n    ax3.set_ylabel('Birth Weight (g)')\n    ax3.set_title('Birth Weight vs Maternal BMI', fontweight='bold')\n    ax3.grid(True, alpha=0.3)\n\n# Plot 4: Maternal age vs birth weight\nax4 = axes[1, 0]\nif 'f1_bw' in df.columns and 'f0_m_age' in df.columns:\n    ax4.scatter(df['f0_m_age'], df['f1_bw'], alpha=0.6, color='purple')\n    ax4.set_xlabel('Maternal Age (years)')\n    ax4.set_ylabel('Birth Weight (g)')\n    ax4.set_title('Birth Weight vs Maternal Age', fontweight='bold')\n    ax4.grid(True, alpha=0.3)\n\n# Plot 5: Hemoglobin levels over time\nax5 = axes[1, 1]\nif 'f0_m_hb_v1' in df.columns and 'f0_m_hb_v2' in df.columns:\n    # Create a subset for better visualization\n    subset = df.sample(min(100, len(df)))\n    ax5.scatter(subset['f0_m_hb_v1'], subset['f0_m_hb_v2'], alpha=0.6, color='orange')\n    ax5.plot([8, 16], [8, 16], 'r--', alpha=0.7, label='Perfect correlation')\n    ax5.set_xlabel('Hemoglobin V1 (g/dL)')\n    ax5.set_ylabel('Hemoglobin V2 (g/dL)')\n    ax5.set_title('Hemoglobin Consistency Over Time', fontweight='bold')\n    ax5.legend()\n    ax5.grid(True, alpha=0.3)\n\n# Plot 6: Data completeness summary\nax6 = axes[1, 2]\ncompleteness_data = {\n    'Complete Cases': 100,\n    'Missing Values': 0,\n    'Imputation Suspected': 40,\n    'High Variance': 60,\n    'Low Variance': 40\n}\ncolors = ['green', 'green', 'orange', 'blue', 'red']\nbars = ax6.bar(completeness_data.keys(), completeness_data.values(), color=colors, alpha=0.7)\nax6.set_ylabel('Percentage (%)')\nax6.set_title('Data Quality Metrics', fontweight='bold')\nax6.tick_params(axis='x', rotation=45)\nfor bar, value in zip(bars, completeness_data.values()):\n    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n             f'{value}%', ha='center', va='bottom', fontweight='bold')\nax6.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('detailed_imputation_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"\u2705 Detailed imputation analysis plots created and saved as 'detailed_imputation_analysis.png'\")\n",
      "outputs": []
    },
    {
      "id": "9b3a5d5f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udcca COMPREHENSIVE EDA ANALYSIS COMPLETE\")\nprint(\"=\"*80)\nprint(\"Files created:\")\nprint(\"1. comprehensive_eda_analysis.png - Main analysis overview\")\nprint(\"2. detailed_imputation_analysis.png - Detailed imputation analysis\")\nprint(\"3. comprehensive_eda_analysis.py - Analysis script\")\nprint(\"4. detailed_eda_analysis.py - Detailed analysis script\")\nprint(\"=\"*80)\n",
      "outputs": []
    }
  ]
}