{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 2: Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.1: Load Phase 1 Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_phase1_results():\n",
        "    \"\"\"Load Phase 1 results and data\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"PHASE 2: FEATURE ENGINEERING\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Load data\n",
        "    data = pd.read_csv('Data/processed/cleaned_dataset_with_engineered_features.csv')\n",
        "    print(f\"Dataset loaded: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
        "    \n",
        "    # Load Phase 1 results\n",
        "    selected_vars_df = pd.read_csv('Data/processed/MLE_Improved/phase1_selected_variables.csv')\n",
        "    selected_vars = selected_vars_df['variable'].tolist()\n",
        "    print(f\"Phase 1 selected variables: {len(selected_vars)}\")\n",
        "    \n",
        "    # Load categories\n",
        "    categories_df = pd.read_csv('Data/processed/MLE_Improved/phase1_variable_categories.csv')\n",
        "    print(f\"Variable categories: {len(categories_df)}\")\n",
        "    \n",
        "    return data, selected_vars, categories_df\n",
        "\n",
        "# Load Phase 1 results\n",
        "data, selected_vars, categories_df = load_phase1_results()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.2: Create Interaction Terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_interaction_terms(data, selected_vars):\n",
        "    \"\"\"Step 2.1: Create interaction terms to capture non-linear relationships\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 2.1: CREATE INTERACTION TERMS\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    interaction_terms = {}\n",
        "    \n",
        "    # BMI × Height interaction\n",
        "    if 'f0_m_bmi_prepreg' in data.columns and 'f0_m_ht' in data.columns:\n",
        "        data['bmi_height_interaction'] = data['f0_m_bmi_prepreg'] * data['f0_m_ht']\n",
        "        interaction_terms['bmi_height_interaction'] = 'BMI × Height'\n",
        "        print(\"+ Created BMI x Height interaction\")\n",
        "    \n",
        "    # Age × Parity interaction\n",
        "    if 'f0_m_age' in data.columns and 'f0_m_parity_v1' in data.columns:\n",
        "        data['age_parity_interaction'] = data['f0_m_age'] * data['f0_m_parity_v1']\n",
        "        interaction_terms['age_parity_interaction'] = 'Age × Parity'\n",
        "        print(\"+ Created Age x Parity interaction\")\n",
        "    \n",
        "    # Education × Socioeconomic interaction\n",
        "    if 'f0_m_edu' in data.columns and 'f0_socio_eco_sc' in data.columns:\n",
        "        data['edu_socio_interaction'] = data['f0_m_edu'] * data['f0_socio_eco_sc']\n",
        "        interaction_terms['edu_socio_interaction'] = 'Education × Socioeconomic'\n",
        "        print(\"+ Created Education × Socioeconomic interaction\")\n",
        "    \n",
        "    # Hemoglobin × Gestational age interaction\n",
        "    if 'f0_m_hb_v1' in data.columns and 'f0_m_GA_V1' in data.columns:\n",
        "        data['hb_ga_interaction'] = data['f0_m_hb_v1'] * data['f0_m_GA_V1']\n",
        "        interaction_terms['hb_ga_interaction'] = 'Hemoglobin × Gestational Age'\n",
        "        print(\"+ Created Hemoglobin × Gestational Age interaction\")\n",
        "    \n",
        "    # Weight × Height interaction\n",
        "    if 'f0_m_wt_prepreg' in data.columns and 'f0_m_ht' in data.columns:\n",
        "        data['wt_ht_interaction'] = data['f0_m_wt_prepreg'] * data['f0_m_ht']\n",
        "        interaction_terms['wt_ht_interaction'] = 'Weight × Height'\n",
        "        print(\"+ Created Weight × Height interaction\")\n",
        "    \n",
        "    # Additional meaningful interactions\n",
        "    # BMI × Age interaction\n",
        "    if 'f0_m_bmi_prepreg' in data.columns and 'f0_m_age' in data.columns:\n",
        "        data['bmi_age_interaction'] = data['f0_m_bmi_prepreg'] * data['f0_m_age']\n",
        "        interaction_terms['bmi_age_interaction'] = 'BMI × Age'\n",
        "        print(\"+ Created BMI × Age interaction\")\n",
        "    \n",
        "    # Parity × Gravida interaction\n",
        "    if 'f0_m_parity_v1' in data.columns and 'f0_m_gravida_v1' in data.columns:\n",
        "        data['parity_gravida_interaction'] = data['f0_m_parity_v1'] * data['f0_m_gravida_v1']\n",
        "        interaction_terms['parity_gravida_interaction'] = 'Parity × Gravida'\n",
        "        print(\"+ Created Parity × Gravida interaction\")\n",
        "    \n",
        "    # Hemoglobin × BMI interaction\n",
        "    if 'f0_m_hb_v1' in data.columns and 'f0_m_bmi_prepreg' in data.columns:\n",
        "        data['hb_bmi_interaction'] = data['f0_m_hb_v1'] * data['f0_m_bmi_prepreg']\n",
        "        interaction_terms['hb_bmi_interaction'] = 'Hemoglobin × BMI'\n",
        "        print(\"+ Created Hemoglobin × BMI interaction\")\n",
        "    \n",
        "    print(f\"\\nTotal interaction terms created: {len(interaction_terms)}\")\n",
        "    return data, interaction_terms\n",
        "\n",
        "# Create interaction terms\n",
        "data, interaction_terms = create_interaction_terms(data, selected_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.3: Create Composite Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_composite_scores(data, selected_vars):\n",
        "    \"\"\"Step 2.2: Create composite scores to combine related variables\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 2.2: CREATE COMPOSITE SCORES\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    composite_scores = {}\n",
        "    \n",
        "    # Maternal Health Index (normalize to 0-100)\n",
        "    health_components = ['f0_m_hb_v1', 'f0_m_glu_f_v1', 'f0_m_sys_bp_r1_v1']\n",
        "    available_health = [col for col in health_components if col in data.columns]\n",
        "    \n",
        "    if len(available_health) >= 2:\n",
        "        # Normalize each component to 0-100 scale\n",
        "        for col in available_health:\n",
        "            if data[col].std() > 0:  # Avoid division by zero\n",
        "                data[f'{col}_normalized'] = ((data[col] - data[col].min()) / \n",
        "                                           (data[col].max() - data[col].min())) * 100\n",
        "        \n",
        "        # Create composite score\n",
        "        normalized_cols = [f'{col}_normalized' for col in available_health]\n",
        "        data['maternal_health_index'] = data[normalized_cols].mean(axis=1)\n",
        "        composite_scores['maternal_health_index'] = f'Maternal Health Index ({len(available_health)} components)'\n",
        "        print(f\"+ Created Maternal Health Index with {len(available_health)} components\")\n",
        "    \n",
        "    # Nutritional Status Score\n",
        "    nutrition_components = ['f0_m_bmi_prepreg', 'f0_m_wt_prepreg', 'f0_m_ht']\n",
        "    available_nutrition = [col for col in nutrition_components if col in data.columns]\n",
        "    \n",
        "    if len(available_nutrition) >= 2:\n",
        "        # Normalize and create composite\n",
        "        for col in available_nutrition:\n",
        "            if data[col].std() > 0:\n",
        "                data[f'{col}_normalized'] = ((data[col] - data[col].min()) / \n",
        "                                           (data[col].max() - data[col].min())) * 100\n",
        "        \n",
        "        normalized_cols = [f'{col}_normalized' for col in available_nutrition]\n",
        "        data['nutritional_status'] = data[normalized_cols].mean(axis=1)\n",
        "        composite_scores['nutritional_status'] = f'Nutritional Status ({len(available_nutrition)} components)'\n",
        "        print(f\"+ Created Nutritional Status Score with {len(available_nutrition)} components\")\n",
        "    \n",
        "    # Pregnancy Risk Score (higher = more risk)\n",
        "    risk_components = ['f0_m_age', 'f0_m_parity_v1', 'f0_m_abor_v1']\n",
        "    available_risk = [col for col in risk_components if col in data.columns]\n",
        "    \n",
        "    if len(available_risk) >= 2:\n",
        "        # Normalize and sum (higher values = more risk)\n",
        "        for col in available_risk:\n",
        "            if data[col].std() > 0:\n",
        "                data[f'{col}_normalized'] = ((data[col] - data[col].min()) / \n",
        "                                           (data[col].max() - data[col].min())) * 100\n",
        "        \n",
        "        normalized_cols = [f'{col}_normalized' for col in available_risk]\n",
        "        data['pregnancy_risk_score'] = data[normalized_cols].sum(axis=1)\n",
        "        composite_scores['pregnancy_risk_score'] = f'Pregnancy Risk Score ({len(available_risk)} components)'\n",
        "        print(f\"+ Created Pregnancy Risk Score with {len(available_risk)} components\")\n",
        "    \n",
        "    # Anthropometric Index\n",
        "    anthro_components = ['f0_m_waist_prepreg', 'f0_m_hip_prepreg']\n",
        "    available_anthro = [col for col in anthro_components if col in data.columns]\n",
        "    \n",
        "    if len(available_anthro) >= 2:\n",
        "        # Normalize and create composite\n",
        "        for col in available_anthro:\n",
        "            if data[col].std() > 0:\n",
        "                data[f'{col}_normalized'] = ((data[col] - data[col].min()) / \n",
        "                                           (data[col].max() - data[col].min())) * 100\n",
        "        \n",
        "        normalized_cols = [f'{col}_normalized' for col in available_anthro]\n",
        "        data['anthropometric_index'] = data[normalized_cols].mean(axis=1)\n",
        "        composite_scores['anthropometric_index'] = f'Anthropometric Index ({len(available_anthro)} components)'\n",
        "        print(f\"+ Created Anthropometric Index with {len(available_anthro)} components\")\n",
        "    \n",
        "    # Gestational Health Index\n",
        "    ga_components = ['f0_m_GA_V1', 'f0_m_GA_V2', 'f0_m_GA_Del']\n",
        "    available_ga = [col for col in ga_components if col in data.columns]\n",
        "    \n",
        "    if len(available_ga) >= 2:\n",
        "        # Normalize and create composite\n",
        "        for col in available_ga:\n",
        "            if data[col].std() > 0:\n",
        "                data[f'{col}_normalized'] = ((data[col] - data[col].min()) / \n",
        "                                           (data[col].max() - data[col].min())) * 100\n",
        "        \n",
        "        normalized_cols = [f'{col}_normalized' for col in available_ga]\n",
        "        data['gestational_health_index'] = data[normalized_cols].mean(axis=1)\n",
        "        composite_scores['gestational_health_index'] = f'Gestational Health Index ({len(available_ga)} components)'\n",
        "        print(f\"+ Created Gestational Health Index with {len(available_ga)} components\")\n",
        "    \n",
        "    print(f\"\\nTotal composite scores created: {len(composite_scores)}\")\n",
        "    return data, composite_scores\n",
        "\n",
        "# Create composite scores\n",
        "data, composite_scores = create_composite_scores(data, selected_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.4: Create Ratio Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_ratio_features(data, selected_vars):\n",
        "    \"\"\"Step 2.3: Create ratio features for meaningful relationships\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 2.3: CREATE RATIO FEATURES\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    ratio_features = {}\n",
        "    \n",
        "    # Waist-to-Hip ratio\n",
        "    if 'f0_m_waist_prepreg' in data.columns and 'f0_m_hip_prepreg' in data.columns:\n",
        "        data['waist_hip_ratio'] = data['f0_m_waist_prepreg'] / data['f0_m_hip_prepreg']\n",
        "        ratio_features['waist_hip_ratio'] = 'Waist-to-Hip Ratio'\n",
        "        print(\"+ Created Waist-to-Hip ratio\")\n",
        "    \n",
        "    # Weight-to-Height ratio\n",
        "    if 'f0_m_wt_prepreg' in data.columns and 'f0_m_ht' in data.columns:\n",
        "        data['wt_ht_ratio'] = data['f0_m_wt_prepreg'] / data['f0_m_ht']\n",
        "        ratio_features['wt_ht_ratio'] = 'Weight-to-Height Ratio'\n",
        "        print(\"+ Created Weight-to-Height ratio\")\n",
        "    \n",
        "    # Hemoglobin-to-Gestational age ratio\n",
        "    if 'f0_m_hb_v1' in data.columns and 'f0_m_GA_V1' in data.columns:\n",
        "        data['hb_ga_ratio'] = data['f0_m_hb_v1'] / data['f0_m_GA_V1']\n",
        "        ratio_features['hb_ga_ratio'] = 'Hemoglobin-to-Gestational Age Ratio'\n",
        "        print(\"+ Created Hemoglobin-to-Gestational Age ratio\")\n",
        "    \n",
        "    # BMI-to-Age ratio\n",
        "    if 'f0_m_bmi_prepreg' in data.columns and 'f0_m_age' in data.columns:\n",
        "        data['bmi_age_ratio'] = data['f0_m_bmi_prepreg'] / data['f0_m_age']\n",
        "        ratio_features['bmi_age_ratio'] = 'BMI-to-Age Ratio'\n",
        "        print(\"+ Created BMI-to-Age ratio\")\n",
        "    \n",
        "    # Parity-to-Gravida ratio\n",
        "    if 'f0_m_parity_v1' in data.columns and 'f0_m_gravida_v1' in data.columns:\n",
        "        # Avoid division by zero\n",
        "        data['parity_gravida_ratio'] = np.where(data['f0_m_gravida_v1'] > 0, \n",
        "                                               data['f0_m_parity_v1'] / data['f0_m_gravida_v1'], 0)\n",
        "        ratio_features['parity_gravida_ratio'] = 'Parity-to-Gravida Ratio'\n",
        "        print(\"+ Created Parity-to-Gravida ratio\")\n",
        "    \n",
        "    # Height-to-Age ratio\n",
        "    if 'f0_m_ht' in data.columns and 'f0_m_age' in data.columns:\n",
        "        data['ht_age_ratio'] = data['f0_m_ht'] / data['f0_m_age']\n",
        "        ratio_features['ht_age_ratio'] = 'Height-to-Age Ratio'\n",
        "        print(\"+ Created Height-to-Age ratio\")\n",
        "    \n",
        "    # Hemoglobin-to-BMI ratio\n",
        "    if 'f0_m_hb_v1' in data.columns and 'f0_m_bmi_prepreg' in data.columns:\n",
        "        data['hb_bmi_ratio'] = data['f0_m_hb_v1'] / data['f0_m_bmi_prepreg']\n",
        "        ratio_features['hb_bmi_ratio'] = 'Hemoglobin-to-BMI Ratio'\n",
        "        print(\"+ Created Hemoglobin-to-BMI ratio\")\n",
        "    \n",
        "    # Placental weight-to-Birth weight ratio\n",
        "    if 'f0_m_plac_wt' in data.columns and 'f1_bw' in data.columns:\n",
        "        data['plac_bw_ratio'] = data['f0_m_plac_wt'] / data['f1_bw']\n",
        "        ratio_features['plac_bw_ratio'] = 'Placental Weight-to-Birth Weight Ratio'\n",
        "        print(\"+ Created Placental Weight-to-Birth Weight ratio\")\n",
        "    \n",
        "    print(f\"\\nTotal ratio features created: {len(ratio_features)}\")\n",
        "    return data, ratio_features\n",
        "\n",
        "# Create ratio features\n",
        "data, ratio_features = create_ratio_features(data, selected_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.5: Handle Categorical Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def handle_categorical_variables(data, selected_vars):\n",
        "    \"\"\"Step 2.4: Handle categorical variables properly\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 2.4: HANDLE CATEGORICAL VARIABLES\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    categorical_encodings = {}\n",
        "    \n",
        "    # Identify categorical variables\n",
        "    categorical_vars = []\n",
        "    for var in selected_vars:\n",
        "        if var in data.columns:\n",
        "            if data[var].dtype == 'object' or data[var].nunique() < 10:\n",
        "                categorical_vars.append(var)\n",
        "    \n",
        "    print(f\"Identified categorical variables: {categorical_vars}\")\n",
        "    \n",
        "    # Handle each categorical variable\n",
        "    for var in categorical_vars:\n",
        "        if var in data.columns:\n",
        "            unique_values = data[var].nunique()\n",
        "            print(f\"\\nProcessing {var}: {unique_values} unique values\")\n",
        "            \n",
        "            if unique_values <= 5:  # Small number of categories - use one-hot encoding\n",
        "                # Create dummy variables\n",
        "                dummies = pd.get_dummies(data[var], prefix=var, dummy_na=True)\n",
        "                data = pd.concat([data, dummies], axis=1)\n",
        "                \n",
        "                # Store encoding info\n",
        "                categorical_encodings[var] = {\n",
        "                    'method': 'one_hot',\n",
        "                    'columns': dummies.columns.tolist()\n",
        "                }\n",
        "                print(f\"  + One-hot encoded into {len(dummies.columns)} columns\")\n",
        "                \n",
        "            else:  # Many categories - use label encoding\n",
        "                le = LabelEncoder()\n",
        "                data[f'{var}_encoded'] = le.fit_transform(data[var].astype(str))\n",
        "                \n",
        "                # Store encoding info\n",
        "                categorical_encodings[var] = {\n",
        "                    'method': 'label',\n",
        "                    'column': f'{var}_encoded',\n",
        "                    'classes': le.classes_.tolist()\n",
        "                }\n",
        "                print(f\"  + Label encoded into {var}_encoded\")\n",
        "    \n",
        "    # Special handling for specific variables\n",
        "    # Child sex (binary)\n",
        "    if 'f1_sex' in data.columns:\n",
        "        if data['f1_sex'].dtype == 'object':\n",
        "            data['f1_sex_male'] = (data['f1_sex'] == 'Male').astype(int)\n",
        "            data['f1_sex_female'] = (data['f1_sex'] == 'Female').astype(int)\n",
        "            categorical_encodings['f1_sex'] = {\n",
        "                'method': 'binary',\n",
        "                'columns': ['f1_sex_male', 'f1_sex_female']\n",
        "            }\n",
        "            print(\"+ Created binary encoding for child sex\")\n",
        "    \n",
        "    # Delivery mode\n",
        "    if 'f0_m_del_mode' in data.columns:\n",
        "        if data['f0_m_del_mode'].dtype == 'object':\n",
        "            data['f0_m_del_mode_encoded'] = LabelEncoder().fit_transform(data['f0_m_del_mode'].astype(str))\n",
        "            categorical_encodings['f0_m_del_mode'] = {\n",
        "                'method': 'label',\n",
        "                'column': 'f0_m_del_mode_encoded'\n",
        "            }\n",
        "            print(\"+ Created label encoding for delivery mode\")\n",
        "    \n",
        "    print(f\"\\nTotal categorical variables processed: {len(categorical_encodings)}\")\n",
        "    return data, categorical_encodings\n",
        "\n",
        "# Handle categorical variables\n",
        "data, categorical_encodings = handle_categorical_variables(data, selected_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.6: Create Polynomial Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_polynomial_features(data, selected_vars):\n",
        "    \"\"\"Create polynomial features for key variables\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CREATE POLYNOMIAL FEATURES\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    polynomial_features = {}\n",
        "    \n",
        "    # Key variables for polynomial features\n",
        "    key_vars = ['f0_m_age', 'f0_m_bmi_prepreg', 'f0_m_ht', 'f0_m_wt_prepreg', 'f0_m_GA_Del']\n",
        "    \n",
        "    for var in key_vars:\n",
        "        if var in data.columns:\n",
        "            # Square term\n",
        "            data[f'{var}_squared'] = data[var] ** 2\n",
        "            polynomial_features[f'{var}_squared'] = f'{var} squared'\n",
        "            \n",
        "            # Square root term (if all values are positive)\n",
        "            if (data[var] >= 0).all():\n",
        "                data[f'{var}_sqrt'] = np.sqrt(data[var])\n",
        "                polynomial_features[f'{var}_sqrt'] = f'{var} square root'\n",
        "            \n",
        "            print(f\"+ Created polynomial features for {var}\")\n",
        "    \n",
        "    print(f\"\\nTotal polynomial features created: {len(polynomial_features)}\")\n",
        "    return data, polynomial_features\n",
        "\n",
        "# Create polynomial features\n",
        "data, polynomial_features = create_polynomial_features(data, selected_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.7: Create Feature Engineering Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_feature_engineering_visualizations(data, interaction_terms, composite_scores, ratio_features):\n",
        "    \"\"\"Create visualizations for feature engineering results\"\"\"\n",
        "    print(\"\\nCreating feature engineering visualizations...\")\n",
        "    \n",
        "    # Set up the plotting style\n",
        "    plt.style.use('default')\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    \n",
        "    # 1. Feature engineering summary\n",
        "    feature_types = ['Original', 'Interactions', 'Composite Scores', 'Ratios', 'Polynomial']\n",
        "    feature_counts = [\n",
        "        len([col for col in data.columns if not any(x in col for x in ['_interaction', '_index', '_ratio', '_squared', '_sqrt', '_encoded', '_normalized'])]),\n",
        "        len(interaction_terms),\n",
        "        len(composite_scores),\n",
        "        len(ratio_features),\n",
        "        len([col for col in data.columns if any(x in col for x in ['_squared', '_sqrt'])])\n",
        "    ]\n",
        "    \n",
        "    axes[0, 0].bar(feature_types, feature_counts, color=['blue', 'green', 'orange', 'red', 'purple'])\n",
        "    axes[0, 0].set_title('Feature Engineering Summary')\n",
        "    axes[0, 0].set_ylabel('Number of Features')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for i, v in enumerate(feature_counts):\n",
        "        axes[0, 0].text(i, v + 0.1, str(v), ha='center', va='bottom')\n",
        "    \n",
        "    # 2. Interaction terms correlation with target\n",
        "    if interaction_terms and 'f1_bw' in data.columns:\n",
        "        interaction_corrs = []\n",
        "        interaction_names = []\n",
        "        \n",
        "        for term in interaction_terms.keys():\n",
        "            if term in data.columns:\n",
        "                corr = data[term].corr(data['f1_bw'])\n",
        "                if not pd.isna(corr):\n",
        "                    interaction_corrs.append(abs(corr))\n",
        "                    interaction_names.append(term.replace('_interaction', ''))\n",
        "        \n",
        "        if interaction_corrs:\n",
        "            axes[0, 1].barh(range(len(interaction_names)), interaction_corrs)\n",
        "            axes[0, 1].set_yticks(range(len(interaction_names)))\n",
        "            axes[0, 1].set_yticklabels(interaction_names, fontsize=8)\n",
        "            axes[0, 1].set_xlabel('Absolute Correlation with Birthweight')\n",
        "            axes[0, 1].set_title('Interaction Terms Correlation')\n",
        "    \n",
        "    # 3. Composite scores distribution\n",
        "    if composite_scores and 'f1_bw' in data.columns:\n",
        "        composite_corrs = []\n",
        "        composite_names = []\n",
        "        \n",
        "        for score in composite_scores.keys():\n",
        "            if score in data.columns:\n",
        "                corr = data[score].corr(data['f1_bw'])\n",
        "                if not pd.isna(corr):\n",
        "                    composite_corrs.append(abs(corr))\n",
        "                    composite_names.append(score.replace('_index', '').replace('_score', ''))\n",
        "        \n",
        "        if composite_corrs:\n",
        "            axes[0, 2].barh(range(len(composite_names)), composite_corrs)\n",
        "            axes[0, 2].set_yticks(range(len(composite_names)))\n",
        "            axes[0, 2].set_yticklabels(composite_names, fontsize=8)\n",
        "            axes[0, 2].set_xlabel('Absolute Correlation with Birthweight')\n",
        "            axes[0, 2].set_title('Composite Scores Correlation')\n",
        "    \n",
        "    # 4. Ratio features correlation\n",
        "    if ratio_features and 'f1_bw' in data.columns:\n",
        "        ratio_corrs = []\n",
        "        ratio_names = []\n",
        "        \n",
        "        for ratio in ratio_features.keys():\n",
        "            if ratio in data.columns:\n",
        "                corr = data[ratio].corr(data['f1_bw'])\n",
        "                if not pd.isna(corr):\n",
        "                    ratio_corrs.append(abs(corr))\n",
        "                    ratio_names.append(ratio.replace('_ratio', ''))\n",
        "        \n",
        "        if ratio_corrs:\n",
        "            axes[1, 0].barh(range(len(ratio_names)), ratio_corrs)\n",
        "            axes[1, 0].set_yticks(range(len(ratio_names)))\n",
        "            axes[1, 0].set_yticklabels(ratio_names, fontsize=8)\n",
        "            axes[1, 0].set_xlabel('Absolute Correlation with Birthweight')\n",
        "            axes[1, 0].set_title('Ratio Features Correlation')\n",
        "    \n",
        "    # 5. Feature importance by type\n",
        "    all_features = list(interaction_terms.keys()) + list(composite_scores.keys()) + list(ratio_features.keys())\n",
        "    if all_features and 'f1_bw' in data.columns:\n",
        "        feature_corrs = []\n",
        "        for feature in all_features:\n",
        "            if feature in data.columns:\n",
        "                corr = data[feature].corr(data['f1_bw'])\n",
        "                if not pd.isna(corr):\n",
        "                    feature_corrs.append(abs(corr))\n",
        "        \n",
        "        if feature_corrs:\n",
        "            axes[1, 1].hist(feature_corrs, bins=10, alpha=0.7, edgecolor='black')\n",
        "            axes[1, 1].set_xlabel('Absolute Correlation with Birthweight')\n",
        "            axes[1, 1].set_ylabel('Frequency')\n",
        "            axes[1, 1].set_title('Engineered Features Correlation Distribution')\n",
        "    \n",
        "    # 6. Total features count\n",
        "    total_original = len([col for col in data.columns if not any(x in col for x in ['_interaction', '_index', '_ratio', '_squared', '_sqrt', '_encoded', '_normalized'])])\n",
        "    total_engineered = len(data.columns) - total_original\n",
        "    \n",
        "    axes[1, 2].pie([total_original, total_engineered], \n",
        "                   labels=['Original Features', 'Engineered Features'], \n",
        "                   autopct='%1.1f%%',\n",
        "                   colors=['lightblue', 'lightgreen'])\n",
        "    axes[1, 2].set_title(f'Feature Count\\nTotal: {len(data.columns)} features')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('PLOTS/MLE_Improved/phase2_feature_engineering_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    print(\"Visualizations saved to PLOTS/MLE_Improved/phase2_feature_engineering_analysis.png\")\n",
        "\n",
        "# Create visualizations\n",
        "create_feature_engineering_visualizations(data, interaction_terms, composite_scores, ratio_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_phase2_results(data, interaction_terms, composite_scores, ratio_features, categorical_encodings, polynomial_features):\n",
        "    \"\"\"Save Phase 2 results for next phases\"\"\"\n",
        "    print(\"\\nSaving Phase 2 results...\")\n",
        "    \n",
        "    # Create results directory if it doesn't exist\n",
        "    import os\n",
        "    os.makedirs('Data/processed/MLE_Improved', exist_ok=True)\n",
        "    \n",
        "    # Save the engineered dataset\n",
        "    data.to_csv('Data/processed/MLE_Improved/phase2_engineered_dataset.csv', index=False)\n",
        "    print(f\"+ Saved engineered dataset: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
        "    \n",
        "    # Save feature engineering summary\n",
        "    feature_summary = {\n",
        "        'phase': 'Phase 2: Feature Engineering',\n",
        "        'original_features': len([col for col in data.columns if not any(x in col for x in ['_interaction', '_index', '_ratio', '_squared', '_sqrt', '_encoded', '_normalized'])]),\n",
        "        'total_features': len(data.columns),\n",
        "        'engineered_features': len(data.columns) - len([col for col in data.columns if not any(x in col for x in ['_interaction', '_index', '_ratio', '_squared', '_sqrt', '_encoded', '_normalized'])]),\n",
        "        'interaction_terms': len(interaction_terms),\n",
        "        'composite_scores': len(composite_scores),\n",
        "        'ratio_features': len(ratio_features),\n",
        "        'categorical_encodings': len(categorical_encodings),\n",
        "        'polynomial_features': len(polynomial_features),\n",
        "        'expected_impact': '10-20% RMSE reduction'\n",
        "    }\n",
        "    \n",
        "    import json\n",
        "    with open('Data/processed/MLE_Improved/phase2_summary.json', 'w') as f:\n",
        "        json.dump(feature_summary, f, indent=2)\n",
        "    \n",
        "    # Save detailed feature information\n",
        "    feature_details = {\n",
        "        'interaction_terms': interaction_terms,\n",
        "        'composite_scores': composite_scores,\n",
        "        'ratio_features': ratio_features,\n",
        "        'categorical_encodings': categorical_encodings,\n",
        "        'polynomial_features': polynomial_features\n",
        "    }\n",
        "    \n",
        "    with open('Data/processed/MLE_Improved/phase2_feature_details.json', 'w') as f:\n",
        "        json.dump(feature_details, f, indent=2)\n",
        "    \n",
        "    print(\"Phase 2 results saved successfully!\")\n",
        "\n",
        "# Save Phase 2 results\n",
        "save_phase2_results(data, interaction_terms, composite_scores, ratio_features, categorical_encodings, polynomial_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 2 Completion Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 2 COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"+ Original features: {len([col for col in data.columns if not any(x in col for x in ['_interaction', '_index', '_ratio', '_squared', '_sqrt', '_encoded', '_normalized'])])}\")\n",
        "print(f\"+ Total features: {len(data.columns)}\")\n",
        "print(f\"+ Engineered features: {len(data.columns) - len([col for col in data.columns if not any(x in col for x in ['_interaction', '_index', '_ratio', '_squared', '_sqrt', '_encoded', '_normalized'])])}\")\n",
        "print(f\"+ Interaction terms: {len(interaction_terms)}\")\n",
        "print(f\"+ Composite scores: {len(composite_scores)}\")\n",
        "print(f\"+ Ratio features: {len(ratio_features)}\")\n",
        "print(f\"+ Ready for Phase 3: Advanced ML Models\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
