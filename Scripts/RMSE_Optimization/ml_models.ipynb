{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Advanced Machine Learning Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import json\n",
        "import warnings\n",
        "import logging\n",
        "import time\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.1: Setup Logging and Utility Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure logging\n",
        "def setup_logging():\n",
        "    \"\"\"Setup comprehensive logging system\"\"\"\n",
        "    # Create logs directory if it doesn't exist\n",
        "    import os\n",
        "    os.makedirs('logs', exist_ok=True)\n",
        "    \n",
        "    # Create logger\n",
        "    logger = logging.getLogger('phase3_ml_models')\n",
        "    logger.setLevel(logging.INFO)\n",
        "    \n",
        "    # Clear any existing handlers\n",
        "    for handler in logger.handlers[:]:\n",
        "        logger.removeHandler(handler)\n",
        "    \n",
        "    # Create formatters\n",
        "    detailed_formatter = logging.Formatter(\n",
        "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "        datefmt='%Y-%m-%d %H:%M:%S'\n",
        "    )\n",
        "    \n",
        "    simple_formatter = logging.Formatter('%(levelname)s: %(message)s')\n",
        "    \n",
        "    # File handler for detailed logs\n",
        "    file_handler = logging.FileHandler(f'logs/phase3_ml_models_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_handler.setFormatter(detailed_formatter)\n",
        "    \n",
        "    # Console handler for important messages\n",
        "    console_handler = logging.StreamHandler(sys.stdout)\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "    console_handler.setFormatter(simple_formatter)\n",
        "    \n",
        "    # Add handlers to logger\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(console_handler)\n",
        "    \n",
        "    return logger\n",
        "\n",
        "# Global logger instance\n",
        "logger = setup_logging()\n",
        "\n",
        "class CustomEnsemble:\n",
        "    \"\"\"Custom ensemble model that handles different scaling for different models\"\"\"\n",
        "    def __init__(self, rf_model, xgb_model, nn_model, nn_scaler):\n",
        "        self.rf_model = rf_model\n",
        "        self.xgb_model = xgb_model\n",
        "        self.nn_model = nn_model\n",
        "        self.nn_scaler = nn_scaler\n",
        "    \n",
        "    def predict(self, X):\n",
        "        rf_pred = self.rf_model.predict(X)\n",
        "        xgb_pred = self.xgb_model.predict(X)\n",
        "        X_nn = self.nn_scaler.transform(X)\n",
        "        nn_pred = self.nn_model.predict(X_nn)\n",
        "        \n",
        "        # Simple average ensemble\n",
        "        return (rf_pred + xgb_pred + nn_pred) / 3\n",
        "\n",
        "class ProgressTracker:\n",
        "    \"\"\"Track progress and timing for different phases\"\"\"\n",
        "    \n",
        "    def __init__(self, total_steps, description=\"Processing\"):\n",
        "        self.total_steps = total_steps\n",
        "        self.current_step = 0\n",
        "        self.description = description\n",
        "        self.start_time = time.time()\n",
        "        self.step_times = []\n",
        "        self.pbar = tqdm(total=total_steps, desc=description, \n",
        "                        bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
        "    \n",
        "    def update(self, step_description=\"\", increment=1):\n",
        "        \"\"\"Update progress with optional description\"\"\"\n",
        "        self.current_step += increment\n",
        "        self.step_times.append(time.time())\n",
        "        \n",
        "        if step_description:\n",
        "            self.pbar.set_description(f\"{self.description}: {step_description}\")\n",
        "        \n",
        "        self.pbar.update(increment)\n",
        "        \n",
        "        # Log progress\n",
        "        elapsed = time.time() - self.start_time\n",
        "        logger.info(f\"Progress: {self.current_step}/{self.total_steps} - {step_description} (Elapsed: {elapsed:.1f}s)\")\n",
        "    \n",
        "    def finish(self, final_description=\"Completed\"):\n",
        "        \"\"\"Finish progress tracking\"\"\"\n",
        "        self.pbar.set_description(f\"{self.description}: {final_description}\")\n",
        "        self.pbar.close()\n",
        "        \n",
        "        total_time = time.time() - self.start_time\n",
        "        logger.info(f\"{self.description} completed in {total_time:.2f} seconds\")\n",
        "        \n",
        "        return total_time\n",
        "\n",
        "def log_phase_start(phase_name, description=\"\"):\n",
        "    \"\"\"Log the start of a new phase\"\"\"\n",
        "    logger.info(\"=\"*60)\n",
        "    logger.info(f\"STARTING: {phase_name}\")\n",
        "    if description:\n",
        "        logger.info(f\"Description: {description}\")\n",
        "    logger.info(\"=\"*60)\n",
        "\n",
        "def log_phase_end(phase_name, duration, results_summary=\"\"):\n",
        "    \"\"\"Log the end of a phase\"\"\"\n",
        "    logger.info(\"=\"*60)\n",
        "    logger.info(f\"COMPLETED: {phase_name}\")\n",
        "    logger.info(f\"Duration: {duration:.2f} seconds\")\n",
        "    if results_summary:\n",
        "        logger.info(f\"Results: {results_summary}\")\n",
        "    logger.info(\"=\"*60)\n",
        "\n",
        "print(\"Logging and utility classes setup completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.2: Load Phase 2 Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_phase2_results():\n",
        "    \"\"\"Load Phase 2 results and engineered dataset\"\"\"\n",
        "    log_phase_start(\"Phase 3: Advanced Machine Learning Models\", \n",
        "                   \"Implementing Random Forest, XGBoost, Neural Network, and Ensemble models\")\n",
        "    \n",
        "    logger.info(\"Loading Phase 2 engineered dataset...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Load engineered dataset\n",
        "    data = pd.read_csv('Data/processed/MLE_Improved/phase2_engineered_dataset.csv')\n",
        "    logger.info(f\"Engineered dataset loaded: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
        "    \n",
        "    # Load Phase 2 summary\n",
        "    with open('Data/processed/MLE_Improved/phase2_summary.json', 'r') as f:\n",
        "        phase2_summary = json.load(f)\n",
        "    \n",
        "    logger.info(f\"Original features: {phase2_summary['original_features']}\")\n",
        "    logger.info(f\"Engineered features: {phase2_summary['engineered_features']}\")\n",
        "    logger.info(f\"Total features: {phase2_summary['total_features']}\")\n",
        "    \n",
        "    duration = time.time() - start_time\n",
        "    logger.info(f\"Data loading completed in {duration:.2f} seconds\")\n",
        "    \n",
        "    return data, phase2_summary\n",
        "\n",
        "# Load Phase 2 results\n",
        "data, phase2_summary = load_phase2_results()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.3: Prepare Data for ML Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data_for_ml(data):\n",
        "    \"\"\"Step 3.1: Prepare data for machine learning models\"\"\"\n",
        "    log_phase_start(\"Step 3.1: Data Preparation\", \"Preparing data for ML models\")\n",
        "    \n",
        "    # Initialize progress tracker\n",
        "    progress = ProgressTracker(6, \"Data Preparation\")\n",
        "    \n",
        "    # Define target variable\n",
        "    progress.update(\"Defining target variable and features\")\n",
        "    target_var = 'f1_bw'\n",
        "    if target_var not in data.columns:\n",
        "        raise ValueError(f\"Target variable {target_var} not found in dataset\")\n",
        "    \n",
        "    # Select features (exclude target and non-predictive columns)\n",
        "    exclude_cols = [target_var, 'Unnamed: 0', 'row_index', 'row_index.1', 'LBW_flag']\n",
        "    feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
        "    \n",
        "    logger.info(f\"Target variable: {target_var}\")\n",
        "    logger.info(f\"Feature columns: {len(feature_cols)}\")\n",
        "    \n",
        "    # Prepare feature matrix and target vector\n",
        "    progress.update(\"Creating feature matrix and target vector\")\n",
        "    X = data[feature_cols].copy()\n",
        "    y = data[target_var].copy()\n",
        "    \n",
        "    logger.info(f\"Feature matrix shape: {X.shape}\")\n",
        "    logger.info(f\"Target vector shape: {y.shape}\")\n",
        "    \n",
        "    # Handle missing data and infinite values\n",
        "    progress.update(\"Handling missing data and infinite values\")\n",
        "    missing_before = X.isnull().sum().sum()\n",
        "    inf_before = np.isinf(X).sum().sum()\n",
        "    logger.info(f\"Missing values before cleaning: {missing_before}\")\n",
        "    logger.info(f\"Infinite values before cleaning: {inf_before}\")\n",
        "    \n",
        "    # Replace infinite values with NaN\n",
        "    X = X.replace([np.inf, -np.inf], np.nan)\n",
        "    \n",
        "    if missing_before > 0 or inf_before > 0:\n",
        "        logger.info(\"Applying iterative imputation...\")\n",
        "        imputer = IterativeImputer(random_state=42, max_iter=10)\n",
        "        X_imputed = imputer.fit_transform(X)\n",
        "        X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
        "        \n",
        "        missing_after = X.isnull().sum().sum()\n",
        "        inf_after = np.isinf(X).sum().sum()\n",
        "        logger.info(f\"Missing values after imputation: {missing_after}\")\n",
        "        logger.info(f\"Infinite values after imputation: {inf_after}\")\n",
        "    else:\n",
        "        logger.info(\"No missing or infinite values found\")\n",
        "    \n",
        "    # Split data into train/validation/test sets\n",
        "    progress.update(\"Splitting data into train/validation/test sets\")\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X, y, test_size=0.4, random_state=42, stratify=None\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=None\n",
        "    )\n",
        "    \n",
        "    logger.info(f\"Training set: {X_train.shape[0]} samples\")\n",
        "    logger.info(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "    logger.info(f\"Test set: {X_test.shape[0]} samples\")\n",
        "    \n",
        "    # Scale features for models that need it\n",
        "    progress.update(\"Scaling features for ML models\")\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Convert back to DataFrames\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
        "    X_val_scaled = pd.DataFrame(X_val_scaled, columns=X.columns, index=X_val.index)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
        "    \n",
        "    # Finish progress tracking\n",
        "    duration = progress.finish(\"Data preparation completed successfully!\")\n",
        "    log_phase_end(\"Step 3.1: Data Preparation\", duration, \n",
        "                 f\"Prepared {len(feature_cols)} features for {X_train.shape[0]} training samples\")\n",
        "    \n",
        "    return (X_train, X_val, X_test, y_train, y_val, y_test, \n",
        "            X_train_scaled, X_val_scaled, X_test_scaled, scaler, feature_cols)\n",
        "\n",
        "# Prepare data for ML models\n",
        "(X_train, X_val, X_test, y_train, y_val, y_test, \n",
        " X_train_scaled, X_val_scaled, X_test_scaled, scaler, feature_cols) = prepare_data_for_ml(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.4: Implement Random Forest Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred, set_name):\n",
        "    \"\"\"Calculate comprehensive metrics for model evaluation\"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    correlation = np.corrcoef(y_true, y_pred)[0, 1]\n",
        "    \n",
        "    print(f\"{set_name} - RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.4f}, MAPE: {mape:.2f}%, Corr: {correlation:.4f}\")\n",
        "    \n",
        "    return {\n",
        "        'rmse': rmse, 'mae': mae, 'r2': r2, 'mape': mape, 'correlation': correlation\n",
        "    }\n",
        "\n",
        "def implement_random_forest(X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "    \"\"\"Step 3.2: Implement Random Forest model\"\"\"\n",
        "    log_phase_start(\"Step 3.2: Random Forest Model\", \"Training Random Forest with 100 estimators\")\n",
        "    \n",
        "    # Initialize progress tracker\n",
        "    progress = ProgressTracker(4, \"Random Forest Training\")\n",
        "    \n",
        "    # Random Forest model\n",
        "    progress.update(\"Initializing Random Forest model\")\n",
        "    rf_model = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    logger.info(\"Random Forest parameters:\")\n",
        "    logger.info(f\"  - n_estimators: {rf_model.n_estimators}\")\n",
        "    logger.info(f\"  - max_depth: {rf_model.max_depth}\")\n",
        "    logger.info(f\"  - min_samples_split: {rf_model.min_samples_split}\")\n",
        "    logger.info(f\"  - min_samples_leaf: {rf_model.min_samples_leaf}\")\n",
        "    \n",
        "    # Training with progress tracking\n",
        "    progress.update(\"Training Random Forest model (this may take a while...)\")\n",
        "    start_time = time.time()\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    logger.info(f\"Random Forest training completed in {training_time:.2f} seconds\")\n",
        "    \n",
        "    # Make predictions\n",
        "    progress.update(\"Making predictions on train/validation/test sets\")\n",
        "    y_pred_train = rf_model.predict(X_train)\n",
        "    y_pred_val = rf_model.predict(X_val)\n",
        "    y_pred_test = rf_model.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    progress.update(\"Calculating performance metrics\")\n",
        "    train_metrics = calculate_metrics(y_train, y_pred_train, \"Random Forest Training\")\n",
        "    val_metrics = calculate_metrics(y_val, y_pred_val, \"Random Forest Validation\")\n",
        "    test_metrics = calculate_metrics(y_test, y_pred_test, \"Random Forest Test\")\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': rf_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    logger.info(\"Top 10 Most Important Features (Random Forest):\")\n",
        "    for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
        "        logger.info(f\"  {i+1:2d}. {row['feature']:<30} {row['importance']:.4f}\")\n",
        "    \n",
        "    # Finish progress tracking\n",
        "    duration = progress.finish(\"Random Forest training completed!\")\n",
        "    log_phase_end(\"Step 3.2: Random Forest Model\", duration, \n",
        "                 f\"Test RMSE: {test_metrics['rmse']:.2f}, R²: {test_metrics['r2']:.4f}\")\n",
        "    \n",
        "    return rf_model, train_metrics, val_metrics, test_metrics, feature_importance\n",
        "\n",
        "# Implement Random Forest model\n",
        "rf_model, rf_train_metrics, rf_val_metrics, rf_test_metrics, rf_importance = implement_random_forest(\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.5: Implement XGBoost Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def implement_xgboost(X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "    \"\"\"Step 3.3: Implement XGBoost model\"\"\"\n",
        "    log_phase_start(\"Step 3.3: XGBoost Model\", \"Training XGBoost with gradient boosting\")\n",
        "    \n",
        "    # Initialize progress tracker\n",
        "    progress = ProgressTracker(4, \"XGBoost Training\")\n",
        "    \n",
        "    # XGBoost model\n",
        "    progress.update(\"Initializing XGBoost model\")\n",
        "    xgb_model = xgb.XGBRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    logger.info(\"XGBoost parameters:\")\n",
        "    logger.info(f\"  - n_estimators: {xgb_model.n_estimators}\")\n",
        "    logger.info(f\"  - max_depth: {xgb_model.max_depth}\")\n",
        "    logger.info(f\"  - learning_rate: {xgb_model.learning_rate}\")\n",
        "    logger.info(f\"  - subsample: {xgb_model.subsample}\")\n",
        "    logger.info(f\"  - colsample_bytree: {xgb_model.colsample_bytree}\")\n",
        "    \n",
        "    # Training with progress tracking\n",
        "    progress.update(\"Training XGBoost model (gradient boosting in progress...)\")\n",
        "    start_time = time.time()\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    logger.info(f\"XGBoost training completed in {training_time:.2f} seconds\")\n",
        "    \n",
        "    # Make predictions\n",
        "    progress.update(\"Making predictions on train/validation/test sets\")\n",
        "    y_pred_train = xgb_model.predict(X_train)\n",
        "    y_pred_val = xgb_model.predict(X_val)\n",
        "    y_pred_test = xgb_model.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    progress.update(\"Calculating performance metrics\")\n",
        "    train_metrics = calculate_metrics(y_train, y_pred_train, \"XGBoost Training\")\n",
        "    val_metrics = calculate_metrics(y_val, y_pred_val, \"XGBoost Validation\")\n",
        "    test_metrics = calculate_metrics(y_test, y_pred_test, \"XGBoost Test\")\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X_train.columns,\n",
        "        'importance': xgb_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    logger.info(\"Top 10 Most Important Features (XGBoost):\")\n",
        "    for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
        "        logger.info(f\"  {i+1:2d}. {row['feature']:<30} {row['importance']:.4f}\")\n",
        "    \n",
        "    # Finish progress tracking\n",
        "    duration = progress.finish(\"XGBoost training completed!\")\n",
        "    log_phase_end(\"Step 3.3: XGBoost Model\", duration, \n",
        "                 f\"Test RMSE: {test_metrics['rmse']:.2f}, R²: {test_metrics['r2']:.4f}\")\n",
        "    \n",
        "    return xgb_model, train_metrics, val_metrics, test_metrics, feature_importance\n",
        "\n",
        "# Implement XGBoost model\n",
        "xgb_model, xgb_train_metrics, xgb_val_metrics, xgb_test_metrics, xgb_importance = implement_xgboost(\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.6: Implement Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def implement_neural_network(X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "    \"\"\"Step 3.4: Implement Neural Network model\"\"\"\n",
        "    log_phase_start(\"Step 3.4: Neural Network Model\", \"Training Multi-layer Perceptron with 3 hidden layers\")\n",
        "    \n",
        "    # Initialize progress tracker\n",
        "    progress = ProgressTracker(5, \"Neural Network Training\")\n",
        "    \n",
        "    # Scale data for neural network (0-1 range)\n",
        "    progress.update(\"Scaling data for neural network (MinMax scaling)\")\n",
        "    nn_scaler = MinMaxScaler()\n",
        "    X_train_nn = nn_scaler.fit_transform(X_train)\n",
        "    X_val_nn = nn_scaler.transform(X_val)\n",
        "    X_test_nn = nn_scaler.transform(X_test)\n",
        "    logger.info(\"Data scaled to [0,1] range for neural network\")\n",
        "    \n",
        "    # Neural Network model\n",
        "    progress.update(\"Initializing Neural Network model\")\n",
        "    nn_model = MLPRegressor(\n",
        "        hidden_layer_sizes=(100, 50, 25),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        alpha=0.001,\n",
        "        learning_rate='adaptive',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    logger.info(\"Neural Network architecture:\")\n",
        "    logger.info(f\"  - Hidden layers: {nn_model.hidden_layer_sizes}\")\n",
        "    logger.info(f\"  - Activation: {nn_model.activation}\")\n",
        "    logger.info(f\"  - Solver: {nn_model.solver}\")\n",
        "    logger.info(f\"  - Alpha (L2 regularization): {nn_model.alpha}\")\n",
        "    logger.info(f\"  - Max iterations: {nn_model.max_iter}\")\n",
        "    \n",
        "    # Training with progress tracking\n",
        "    progress.update(\"Training Neural Network model (backpropagation in progress...)\")\n",
        "    start_time = time.time()\n",
        "    nn_model.fit(X_train_nn, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "    logger.info(f\"Neural Network training completed in {training_time:.2f} seconds\")\n",
        "    logger.info(f\"Final loss: {nn_model.loss_:.6f}\")\n",
        "    logger.info(f\"Number of iterations: {nn_model.n_iter_}\")\n",
        "    \n",
        "    # Make predictions\n",
        "    progress.update(\"Making predictions on train/validation/test sets\")\n",
        "    y_pred_train = nn_model.predict(X_train_nn)\n",
        "    y_pred_val = nn_model.predict(X_val_nn)\n",
        "    y_pred_test = nn_model.predict(X_test_nn)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    progress.update(\"Calculating performance metrics\")\n",
        "    train_metrics = calculate_metrics(y_train, y_pred_train, \"Neural Network Training\")\n",
        "    val_metrics = calculate_metrics(y_val, y_pred_val, \"Neural Network Validation\")\n",
        "    test_metrics = calculate_metrics(y_test, y_pred_test, \"Neural Network Test\")\n",
        "    \n",
        "    # Finish progress tracking\n",
        "    duration = progress.finish(\"Neural Network training completed!\")\n",
        "    log_phase_end(\"Step 3.4: Neural Network Model\", duration, \n",
        "                 f\"Test RMSE: {test_metrics['rmse']:.2f}, R²: {test_metrics['r2']:.4f}\")\n",
        "    \n",
        "    return nn_model, train_metrics, val_metrics, test_metrics, nn_scaler\n",
        "\n",
        "# Implement Neural Network model\n",
        "nn_model, nn_train_metrics, nn_val_metrics, nn_test_metrics, nn_scaler = implement_neural_network(\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.7: Implement Ensemble Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def implement_ensemble_model(rf_model, xgb_model, nn_model, nn_scaler, X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "    \"\"\"Step 3.5: Implement Ensemble model\"\"\"\n",
        "    log_phase_start(\"Step 3.5: Ensemble Model\", \"Creating ensemble from Random Forest, XGBoost, and Neural Network\")\n",
        "    \n",
        "    # Initialize progress tracker\n",
        "    progress = ProgressTracker(4, \"Ensemble Training\")\n",
        "    \n",
        "    # Create ensemble model\n",
        "    progress.update(\"Creating custom ensemble model\")\n",
        "    # For neural network, we need to use scaled data\n",
        "    X_train_nn = nn_scaler.transform(X_train)\n",
        "    X_val_nn = nn_scaler.transform(X_val)\n",
        "    X_test_nn = nn_scaler.transform(X_test)\n",
        "    \n",
        "    # Create a custom ensemble that handles different scaling\n",
        "    custom_ensemble = CustomEnsemble(rf_model, xgb_model, nn_model, nn_scaler)\n",
        "    logger.info(\"Custom ensemble created with equal weights for all three models\")\n",
        "    logger.info(\"Ensemble components: Random Forest + XGBoost + Neural Network\")\n",
        "    \n",
        "    # Make predictions\n",
        "    progress.update(\"Making ensemble predictions on all datasets\")\n",
        "    y_pred_train = custom_ensemble.predict(X_train)\n",
        "    y_pred_val = custom_ensemble.predict(X_val)\n",
        "    y_pred_test = custom_ensemble.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    progress.update(\"Calculating ensemble performance metrics\")\n",
        "    train_metrics = calculate_metrics(y_train, y_pred_train, \"Ensemble Training\")\n",
        "    val_metrics = calculate_metrics(y_val, y_pred_val, \"Ensemble Validation\")\n",
        "    test_metrics = calculate_metrics(y_test, y_pred_test, \"Ensemble Test\")\n",
        "    \n",
        "    # Finish progress tracking\n",
        "    duration = progress.finish(\"Ensemble model completed!\")\n",
        "    log_phase_end(\"Step 3.5: Ensemble Model\", duration, \n",
        "                 f\"Test RMSE: {test_metrics['rmse']:.2f}, R²: {test_metrics['r2']:.4f}\")\n",
        "    \n",
        "    return custom_ensemble, train_metrics, val_metrics, test_metrics\n",
        "\n",
        "# Implement Ensemble model\n",
        "ensemble_model, ensemble_train_metrics, ensemble_val_metrics, ensemble_test_metrics = implement_ensemble_model(\n",
        "    rf_model, xgb_model, nn_model, nn_scaler, X_train, X_val, X_test, y_train, y_val, y_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.8: Create Model Comparison Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile results\n",
        "models_results = {\n",
        "    'Random Forest': {\n",
        "        'model': rf_model,\n",
        "        'train_metrics': rf_train_metrics,\n",
        "        'val_metrics': rf_val_metrics,\n",
        "        'test_metrics': rf_test_metrics,\n",
        "        'feature_importance': rf_importance\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': xgb_model,\n",
        "        'train_metrics': xgb_train_metrics,\n",
        "        'val_metrics': xgb_val_metrics,\n",
        "        'test_metrics': xgb_test_metrics,\n",
        "        'feature_importance': xgb_importance\n",
        "    },\n",
        "    'Neural Network': {\n",
        "        'model': nn_model,\n",
        "        'train_metrics': nn_train_metrics,\n",
        "        'val_metrics': nn_val_metrics,\n",
        "        'test_metrics': nn_test_metrics,\n",
        "        'nn_scaler': nn_scaler\n",
        "    },\n",
        "    'Ensemble': {\n",
        "        'model': ensemble_model,\n",
        "        'train_metrics': ensemble_train_metrics,\n",
        "        'val_metrics': ensemble_val_metrics,\n",
        "        'test_metrics': ensemble_test_metrics\n",
        "    }\n",
        "}\n",
        "\n",
        "def create_model_comparison_visualizations(models_results):\n",
        "    \"\"\"Create visualizations comparing all models\"\"\"\n",
        "    log_phase_start(\"Model Comparison Visualizations\", \"Creating comprehensive model performance charts\")\n",
        "    \n",
        "    logger.info(\"Creating model comparison visualizations...\")\n",
        "    \n",
        "    # Set up the plotting style\n",
        "    plt.style.use('default')\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    \n",
        "    # Extract model names and metrics\n",
        "    model_names = list(models_results.keys())\n",
        "    rmse_values = [models_results[name]['test_metrics']['rmse'] for name in model_names]\n",
        "    mae_values = [models_results[name]['test_metrics']['mae'] for name in model_names]\n",
        "    r2_values = [models_results[name]['test_metrics']['r2'] for name in model_names]\n",
        "    \n",
        "    # 1. RMSE comparison\n",
        "    bars1 = axes[0, 0].bar(model_names, rmse_values, color=['blue', 'green', 'orange', 'red'])\n",
        "    axes[0, 0].set_title('RMSE Comparison (Test Set)')\n",
        "    axes[0, 0].set_ylabel('RMSE (grams)')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars1, rmse_values):\n",
        "        height = bar.get_height()\n",
        "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{value:.1f}', ha='center', va='bottom')\n",
        "    \n",
        "    # 2. MAE comparison\n",
        "    bars2 = axes[0, 1].bar(model_names, mae_values, color=['blue', 'green', 'orange', 'red'])\n",
        "    axes[0, 1].set_title('MAE Comparison (Test Set)')\n",
        "    axes[0, 1].set_ylabel('MAE (grams)')\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    for bar, value in zip(bars2, mae_values):\n",
        "        height = bar.get_height()\n",
        "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{value:.1f}', ha='center', va='bottom')\n",
        "    \n",
        "    # 3. R² comparison\n",
        "    bars3 = axes[0, 2].bar(model_names, r2_values, color=['blue', 'green', 'orange', 'red'])\n",
        "    axes[0, 2].set_title('R² Comparison (Test Set)')\n",
        "    axes[0, 2].set_ylabel('R² Score')\n",
        "    axes[0, 2].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    for bar, value in zip(bars3, r2_values):\n",
        "        height = bar.get_height()\n",
        "        axes[0, 2].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{value:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    # 4. Training vs Test RMSE\n",
        "    train_rmse = [models_results[name]['train_metrics']['rmse'] for name in model_names]\n",
        "    test_rmse = [models_results[name]['test_metrics']['rmse'] for name in model_names]\n",
        "    \n",
        "    x = np.arange(len(model_names))\n",
        "    width = 0.35\n",
        "    \n",
        "    axes[1, 0].bar(x - width/2, train_rmse, width, label='Training', alpha=0.8)\n",
        "    axes[1, 0].bar(x + width/2, test_rmse, width, label='Test', alpha=0.8)\n",
        "    axes[1, 0].set_title('Training vs Test RMSE')\n",
        "    axes[1, 0].set_ylabel('RMSE (grams)')\n",
        "    axes[1, 0].set_xticks(x)\n",
        "    axes[1, 0].set_xticklabels(model_names, rotation=45)\n",
        "    axes[1, 0].legend()\n",
        "    \n",
        "    # 5. Model performance radar chart (simplified)\n",
        "    metrics = ['RMSE', 'MAE', 'R²', 'MAPE', 'Correlation']\n",
        "    best_model_idx = np.argmin(rmse_values)\n",
        "    best_model = model_names[best_model_idx]\n",
        "    \n",
        "    # Normalize metrics for radar chart (lower is better for RMSE, MAE, MAPE)\n",
        "    normalized_metrics = []\n",
        "    for i, name in enumerate(model_names):\n",
        "        model_metrics = models_results[name]['test_metrics']\n",
        "        normalized = [\n",
        "            1 - (model_metrics['rmse'] / max(rmse_values)),  # RMSE (inverted)\n",
        "            1 - (model_metrics['mae'] / max(mae_values)),    # MAE (inverted)\n",
        "            model_metrics['r2'],                             # R² (higher better)\n",
        "            1 - (model_metrics['mape'] / 100),              # MAPE (inverted)\n",
        "            model_metrics['correlation']                     # Correlation\n",
        "        ]\n",
        "        normalized_metrics.append(normalized)\n",
        "    \n",
        "    # Plot top 2 models\n",
        "    for i, name in enumerate(model_names[:2]):\n",
        "        axes[1, 1].plot(metrics, normalized_metrics[i], marker='o', label=name)\n",
        "    \n",
        "    axes[1, 1].set_title('Model Performance Comparison')\n",
        "    axes[1, 1].set_ylabel('Normalized Score')\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Improvement over baseline\n",
        "    baseline_rmse = 388.42  # From original MLE\n",
        "    improvements = [(baseline_rmse - rmse) / baseline_rmse * 100 for rmse in rmse_values]\n",
        "    \n",
        "    bars6 = axes[1, 2].bar(model_names, improvements, color=['blue', 'green', 'orange', 'red'])\n",
        "    axes[1, 2].set_title('Improvement over Baseline MLE')\n",
        "    axes[1, 2].set_ylabel('Improvement (%)')\n",
        "    axes[1, 2].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    for bar, value in zip(bars6, improvements):\n",
        "        height = bar.get_height()\n",
        "        axes[1, 2].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{value:.1f}%', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('PLOTS/MLE_Improved/phase3_model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    logger.info(\"Visualizations saved to PLOTS/MLE_Improved/phase3_model_comparison.png\")\n",
        "    log_phase_end(\"Model Comparison Visualizations\", 0, \"6 comprehensive charts created\")\n",
        "\n",
        "# Create visualizations\n",
        "create_model_comparison_visualizations(models_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.9: Save Phase 3 Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_phase3_results(models_results, scaler, feature_cols):\n",
        "    \"\"\"Save Phase 3 results for next phases\"\"\"\n",
        "    log_phase_start(\"Saving Phase 3 Results\", \"Saving models, scalers, and performance metrics\")\n",
        "    \n",
        "    logger.info(\"Saving Phase 3 results...\")\n",
        "    \n",
        "    # Create results directory if it doesn't exist\n",
        "    import os\n",
        "    os.makedirs('Data/processed/MLE_Improved', exist_ok=True)\n",
        "    os.makedirs('Models', exist_ok=True)\n",
        "    \n",
        "    # Save models\n",
        "    for model_name, results in models_results.items():\n",
        "        if 'model' in results:\n",
        "            model_path = f'Models/{model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
        "            joblib.dump(results['model'], model_path)\n",
        "            logger.info(f\"Saved {model_name} model to {model_path}\")\n",
        "    \n",
        "    # Save scaler\n",
        "    joblib.dump(scaler, 'Models/feature_scaler.pkl')\n",
        "    logger.info(\"Saved feature scaler to Models/feature_scaler.pkl\")\n",
        "    \n",
        "    # Save feature names\n",
        "    with open('Models/feature_names.json', 'w') as f:\n",
        "        json.dump(feature_cols, f)\n",
        "    logger.info(\"Saved feature names to Models/feature_names.json\")\n",
        "    \n",
        "    # Save performance results\n",
        "    performance_summary = {\n",
        "        'phase': 'Phase 3: Advanced ML Models',\n",
        "        'models_trained': len(models_results),\n",
        "        'baseline_rmse': 388.42,\n",
        "        'model_performance': {}\n",
        "    }\n",
        "    \n",
        "    for model_name, results in models_results.items():\n",
        "        performance_summary['model_performance'][model_name] = {\n",
        "            'test_rmse': results['test_metrics']['rmse'],\n",
        "            'test_mae': results['test_metrics']['mae'],\n",
        "            'test_r2': results['test_metrics']['r2'],\n",
        "            'improvement_percent': ((388.42 - results['test_metrics']['rmse']) / 388.42) * 100\n",
        "        }\n",
        "    \n",
        "    with open('Data/processed/MLE_Improved/phase3_summary.json', 'w') as f:\n",
        "        json.dump(performance_summary, f, indent=2)\n",
        "    \n",
        "    logger.info(\"Phase 3 results saved successfully!\")\n",
        "    log_phase_end(\"Saving Phase 3 Results\", 0, f\"Saved {len(models_results)} models and performance metrics\")\n",
        "\n",
        "# Save Phase 3 results\n",
        "save_phase3_results(models_results, scaler, feature_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3 Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find best model\n",
        "best_model_name = min(models_results.keys(), \n",
        "                     key=lambda x: models_results[x]['test_metrics']['rmse'])\n",
        "best_rmse = models_results[best_model_name]['test_metrics']['rmse']\n",
        "improvement = ((388.42 - best_rmse) / 388.42) * 100\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 3 COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Models trained: {len(models_results)}\")\n",
        "print(f\"Best model: {best_model_name}\")\n",
        "print(f\"Best RMSE: {best_rmse:.2f} grams\")\n",
        "print(f\"Improvement: {improvement:.1f}%\")\n",
        "print(f\"Ready for Phase 4: Model Optimization\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
