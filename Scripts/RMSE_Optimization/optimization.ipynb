{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 4: Model Optimization and Validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(f'logs/phase4_optimization_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Libraries imported and logging configured!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.1: Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    \"\"\"Load the engineered dataset from Phase 2\"\"\"\n",
        "    try:\n",
        "        data = pd.read_csv('Data/processed/MLE_Improved/phase2_engineered_dataset.csv')\n",
        "        logging.info(f\"Loaded dataset with shape: {data.shape}\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading data: {e}\")\n",
        "        raise\n",
        "\n",
        "def prepare_ml_data(data):\n",
        "    \"\"\"Prepare data for machine learning models\"\"\"\n",
        "    # Load feature names from Phase 2\n",
        "    with open('Data/processed/MLE_Improved/phase2_feature_details.json', 'r') as f:\n",
        "        feature_details = json.load(f)\n",
        "    \n",
        "    # Get final features (excluding target and ID columns)\n",
        "    target_col = 'f1_bw'\n",
        "    id_cols = ['f0_id', 'f1_id'] if 'f0_id' in data.columns else ['f1_id']\n",
        "    \n",
        "    feature_cols = [col for col in data.columns if col not in [target_col] + id_cols]\n",
        "    \n",
        "    # Prepare feature matrix and target\n",
        "    X = data[feature_cols].copy()\n",
        "    y = data[target_col].copy()\n",
        "    \n",
        "    # Handle infinite values and missing values\n",
        "    # Replace infinite values with NaN\n",
        "    X = X.replace([np.inf, -np.inf], np.nan)\n",
        "    \n",
        "    # Check for columns with all NaN values and remove them\n",
        "    all_nan_cols = X.columns[X.isnull().all()].tolist()\n",
        "    if all_nan_cols:\n",
        "        logging.info(f\"Removing {len(all_nan_cols)} columns with all NaN values: {all_nan_cols[:5]}...\")\n",
        "        X = X.drop(columns=all_nan_cols)\n",
        "        feature_cols = [col for col in feature_cols if col not in all_nan_cols]\n",
        "    \n",
        "    # Handle missing values with iterative imputation\n",
        "    from sklearn.experimental import enable_iterative_imputer\n",
        "    from sklearn.impute import IterativeImputer\n",
        "    imputer = IterativeImputer(random_state=42, max_iter=10)\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "    X_imputed = pd.DataFrame(X_imputed, columns=feature_cols)\n",
        "    \n",
        "    # Scale features\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_imputed)\n",
        "    X_scaled = pd.DataFrame(X_scaled, columns=feature_cols)\n",
        "    \n",
        "    # Split data\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X_scaled, y, test_size=0.4, random_state=42\n",
        "    )\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.5, random_state=42\n",
        "    )\n",
        "    \n",
        "    logging.info(f\"Data split - Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "    \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, feature_cols, scaler\n",
        "\n",
        "# Load and prepare data\n",
        "data = load_data()\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, feature_cols, scaler = prepare_ml_data(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.2: XGBoost Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hyperparameter_tuning_xgboost(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Perform hyperparameter tuning for XGBoost\"\"\"\n",
        "    logging.info(\"Starting XGBoost hyperparameter tuning...\")\n",
        "    \n",
        "    # Define parameter grid\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200, 300],\n",
        "        'max_depth': [3, 6, 9, 12],\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'subsample': [0.8, 0.9, 1.0],\n",
        "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "        'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
        "        'reg_lambda': [0, 0.1, 0.5, 1.0]\n",
        "    }\n",
        "    \n",
        "    # Use RandomizedSearchCV for efficiency\n",
        "    xgb_model = XGBRegressor(random_state=42, n_jobs=-1)\n",
        "    \n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=xgb_model,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=50,  # Number of parameter settings sampled\n",
        "        cv=5,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # Fit the model\n",
        "    random_search.fit(X_train, y_train)\n",
        "    \n",
        "    # Get best parameters\n",
        "    best_params = random_search.best_params_\n",
        "    best_score = -random_search.best_score_\n",
        "    \n",
        "    logging.info(f\"Best XGBoost parameters: {best_params}\")\n",
        "    logging.info(f\"Best CV RMSE: {np.sqrt(best_score):.2f}\")\n",
        "    \n",
        "    # Evaluate on validation set\n",
        "    best_xgb = random_search.best_estimator_\n",
        "    y_pred_val = best_xgb.predict(X_val)\n",
        "    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "    val_mae = mean_absolute_error(y_val, y_pred_val)\n",
        "    val_r2 = r2_score(y_val, y_pred_val)\n",
        "    \n",
        "    logging.info(f\"XGBoost Validation - RMSE: {val_rmse:.2f}, MAE: {val_mae:.2f}, R²: {val_r2:.4f}\")\n",
        "    \n",
        "    return best_xgb, best_params, val_rmse\n",
        "\n",
        "# Perform XGBoost hyperparameter tuning\n",
        "best_xgb, xgb_params, xgb_val_rmse = hyperparameter_tuning_xgboost(X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.3: Random Forest Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hyperparameter_tuning_random_forest(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Perform hyperparameter tuning for Random Forest\"\"\"\n",
        "    logging.info(\"Starting Random Forest hyperparameter tuning...\")\n",
        "    \n",
        "    # Define parameter grid\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200, 300],\n",
        "        'max_depth': [5, 10, 15, 20, None],\n",
        "        'min_samples_split': [2, 5, 10, 15],\n",
        "        'min_samples_leaf': [1, 2, 4, 8],\n",
        "        'max_features': ['sqrt', 'log2', 0.5, 0.7, 0.9],\n",
        "        'bootstrap': [True, False]\n",
        "    }\n",
        "    \n",
        "    # Use RandomizedSearchCV for efficiency\n",
        "    rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "    \n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf_model,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=50,\n",
        "        cv=5,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # Fit the model\n",
        "    random_search.fit(X_train, y_train)\n",
        "    \n",
        "    # Get best parameters\n",
        "    best_params = random_search.best_params_\n",
        "    best_score = -random_search.best_score_\n",
        "    \n",
        "    logging.info(f\"Best Random Forest parameters: {best_params}\")\n",
        "    logging.info(f\"Best CV RMSE: {np.sqrt(best_score):.2f}\")\n",
        "    \n",
        "    # Evaluate on validation set\n",
        "    best_rf = random_search.best_estimator_\n",
        "    y_pred_val = best_rf.predict(X_val)\n",
        "    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "    val_mae = mean_absolute_error(y_val, y_pred_val)\n",
        "    val_r2 = r2_score(y_val, y_pred_val)\n",
        "    \n",
        "    logging.info(f\"Random Forest Validation - RMSE: {val_rmse:.2f}, MAE: {val_mae:.2f}, R²: {val_r2:.4f}\")\n",
        "    \n",
        "    return best_rf, best_params, val_rmse\n",
        "\n",
        "# Perform Random Forest hyperparameter tuning\n",
        "best_rf, rf_params, rf_val_rmse = hyperparameter_tuning_random_forest(X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.4: Cross-Validation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_validation_analysis(X_train, y_train, models):\n",
        "    \"\"\"Perform cross-validation analysis for all models\"\"\"\n",
        "    logging.info(\"Starting cross-validation analysis...\")\n",
        "    \n",
        "    cv_results = {}\n",
        "    \n",
        "    for name, model in models.items():\n",
        "        logging.info(f\"Performing CV for {name}...\")\n",
        "        \n",
        "        # 5-fold cross-validation\n",
        "        scores = cross_val_score(\n",
        "            model, X_train, y_train,\n",
        "            cv=5, scoring='neg_mean_squared_error',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        \n",
        "        rmse_scores = np.sqrt(-scores)\n",
        "        \n",
        "        cv_results[name] = {\n",
        "            'mean_rmse': rmse_scores.mean(),\n",
        "            'std_rmse': rmse_scores.std(),\n",
        "            'scores': rmse_scores.tolist()\n",
        "        }\n",
        "        \n",
        "        logging.info(f\"{name} - CV RMSE: {rmse_scores.mean():.2f} ± {rmse_scores.std():.2f}\")\n",
        "    \n",
        "    return cv_results\n",
        "\n",
        "# Perform cross-validation analysis\n",
        "models = {\n",
        "    'XGBoost': best_xgb,\n",
        "    'Random Forest': best_rf\n",
        "}\n",
        "cv_results = cross_validation_analysis(X_train, y_train, models)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.5: Feature Selection Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_selection_analysis(X_train, y_train, X_val, y_val, feature_cols, k_values=[10, 15, 20, 25, 30]):\n",
        "    \"\"\"Perform feature selection analysis\"\"\"\n",
        "    logging.info(\"Starting feature selection analysis...\")\n",
        "    \n",
        "    feature_selection_results = {}\n",
        "    \n",
        "    for k in k_values:\n",
        "        logging.info(f\"Selecting top {k} features...\")\n",
        "        \n",
        "        # SelectKBest with f_regression\n",
        "        selector = SelectKBest(score_func=f_regression, k=k)\n",
        "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "        X_val_selected = selector.transform(X_val)\n",
        "        \n",
        "        # Get selected feature names\n",
        "        selected_features = [feature_cols[i] for i in selector.get_support(indices=True)]\n",
        "        \n",
        "        # Train XGBoost with selected features\n",
        "        xgb_selected = XGBRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=6,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        \n",
        "        xgb_selected.fit(X_train_selected, y_train)\n",
        "        \n",
        "        # Evaluate\n",
        "        y_pred_val = xgb_selected.predict(X_val_selected)\n",
        "        val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "        val_mae = mean_absolute_error(y_val, y_pred_val)\n",
        "        val_r2 = r2_score(y_val, y_pred_val)\n",
        "        \n",
        "        feature_selection_results[k] = {\n",
        "            'selected_features': selected_features,\n",
        "            'val_rmse': val_rmse,\n",
        "            'val_mae': val_mae,\n",
        "            'val_r2': val_r2,\n",
        "            'feature_importance': xgb_selected.feature_importances_.tolist()\n",
        "        }\n",
        "        \n",
        "        logging.info(f\"Top {k} features - Val RMSE: {val_rmse:.2f}, MAE: {val_mae:.2f}, R²: {val_r2:.4f}\")\n",
        "    \n",
        "    # Find optimal number of features\n",
        "    best_k = min(feature_selection_results.keys(), \n",
        "                key=lambda x: feature_selection_results[x]['val_rmse'])\n",
        "    \n",
        "    logging.info(f\"Optimal number of features: {best_k}\")\n",
        "    \n",
        "    return feature_selection_results, best_k\n",
        "\n",
        "# Perform feature selection analysis\n",
        "feature_selection_results, best_k = feature_selection_analysis(\n",
        "    X_train, y_train, X_val, y_val, feature_cols\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.6: Create Optimization Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_optimization_visualizations(cv_results, feature_selection_results, best_k):\n",
        "    \"\"\"Create visualizations for optimization results\"\"\"\n",
        "    logging.info(\"Creating optimization visualizations...\")\n",
        "    \n",
        "    # Set style\n",
        "    plt.style.use('default')\n",
        "    sns.set_palette(\"husl\")\n",
        "    \n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # 1. Cross-validation results\n",
        "    model_names = list(cv_results.keys())\n",
        "    mean_rmse = [cv_results[name]['mean_rmse'] for name in model_names]\n",
        "    std_rmse = [cv_results[name]['std_rmse'] for name in model_names]\n",
        "    \n",
        "    bars = axes[0, 0].bar(model_names, mean_rmse, yerr=std_rmse, capsize=5, alpha=0.7)\n",
        "    axes[0, 0].set_ylabel('RMSE (grams)')\n",
        "    axes[0, 0].set_title('Cross-Validation RMSE Comparison')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, mean, std in zip(bars, mean_rmse, std_rmse):\n",
        "        height = bar.get_height()\n",
        "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + std,\n",
        "                       f'{mean:.1f}±{std:.1f}', ha='center', va='bottom')\n",
        "    \n",
        "    # 2. Feature selection results\n",
        "    k_values = list(feature_selection_results.keys())\n",
        "    rmse_values = [feature_selection_results[k]['val_rmse'] for k in k_values]\n",
        "    \n",
        "    axes[0, 1].plot(k_values, rmse_values, marker='o', linewidth=2, markersize=8)\n",
        "    axes[0, 1].axvline(x=best_k, color='red', linestyle='--', alpha=0.7, label=f'Optimal k={best_k}')\n",
        "    axes[0, 1].set_xlabel('Number of Features')\n",
        "    axes[0, 1].set_ylabel('Validation RMSE (grams)')\n",
        "    axes[0, 1].set_title('Feature Selection Analysis')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    axes[0, 1].legend()\n",
        "    \n",
        "    # Add value labels\n",
        "    for k, rmse in zip(k_values, rmse_values):\n",
        "        axes[0, 1].annotate(f'{rmse:.1f}', (k, rmse), textcoords=\"offset points\", \n",
        "                           xytext=(0,10), ha='center')\n",
        "    \n",
        "    # 3. Feature importance (top 15 from best model)\n",
        "    best_features = feature_selection_results[best_k]['selected_features']\n",
        "    best_importance = feature_selection_results[best_k]['feature_importance']\n",
        "    \n",
        "    # Create DataFrame for sorting\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': best_features,\n",
        "        'importance': best_importance\n",
        "    }).sort_values('importance', ascending=True).tail(15)\n",
        "    \n",
        "    axes[1, 0].barh(range(len(importance_df)), importance_df['importance'])\n",
        "    axes[1, 0].set_yticks(range(len(importance_df)))\n",
        "    axes[1, 0].set_yticklabels(importance_df['feature'])\n",
        "    axes[1, 0].set_xlabel('Feature Importance')\n",
        "    axes[1, 0].set_title(f'Top 15 Feature Importance (k={best_k})')\n",
        "    \n",
        "    # 4. Model comparison summary\n",
        "    # Load previous phase results for comparison\n",
        "    try:\n",
        "        with open('Data/processed/MLE_Improved/phase3_summary.json', 'r') as f:\n",
        "            phase3_results = json.load(f)\n",
        "        \n",
        "        # Compare with previous phase\n",
        "        phase3_rmse = phase3_results['model_performance']['XGBoost']['test_rmse']\n",
        "        current_best_rmse = min(rmse_values)\n",
        "        \n",
        "        comparison_data = ['Phase 3 XGBoost', 'Phase 4 Optimized']\n",
        "        comparison_rmse = [phase3_rmse, current_best_rmse]\n",
        "        colors = ['lightblue', 'lightgreen']\n",
        "        \n",
        "        bars = axes[1, 1].bar(comparison_data, comparison_rmse, color=colors, alpha=0.7)\n",
        "        axes[1, 1].set_ylabel('RMSE (grams)')\n",
        "        axes[1, 1].set_title('Phase 3 vs Phase 4 Performance')\n",
        "        \n",
        "        # Add value labels\n",
        "        for bar, value in zip(bars, comparison_rmse):\n",
        "            height = bar.get_height()\n",
        "            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                           f'{value:.1f}', ha='center', va='bottom')\n",
        "        \n",
        "        # Add improvement percentage\n",
        "        improvement = ((phase3_rmse - current_best_rmse) / phase3_rmse) * 100\n",
        "        axes[1, 1].text(0.5, max(comparison_rmse) * 0.8, \n",
        "                       f'Improvement: {improvement:.1f}%', \n",
        "                       ha='center', va='center', fontsize=12, \n",
        "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        axes[1, 1].text(0.5, 0.5, 'Phase 3 results not found', ha='center', va='center')\n",
        "        axes[1, 1].set_title('Phase Comparison (Data Not Available)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('PLOTS/MLE_Improved/phase4_optimization_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    logging.info(\"Optimization visualizations saved to PLOTS/MLE_Improved/phase4_optimization_analysis.png\")\n",
        "\n",
        "# Create optimization visualizations\n",
        "create_optimization_visualizations(cv_results, feature_selection_results, best_k)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.7: Save Optimization Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_optimization_results(best_xgb, best_rf, cv_results, feature_selection_results, best_k, scaler):\n",
        "    \"\"\"Save optimization results and models\"\"\"\n",
        "    logging.info(\"Saving optimization results...\")\n",
        "    \n",
        "    # Save optimized models\n",
        "    joblib.dump(best_xgb, 'Models/optimized_xgboost_model.pkl')\n",
        "    joblib.dump(best_rf, 'Models/optimized_random_forest_model.pkl')\n",
        "    joblib.dump(scaler, 'Models/optimization_scaler.pkl')\n",
        "    \n",
        "    # Save feature selection results\n",
        "    best_features = feature_selection_results[best_k]['selected_features']\n",
        "    with open('Models/optimized_feature_names.json', 'w') as f:\n",
        "        json.dump(best_features, f, indent=2)\n",
        "    \n",
        "    # Create comprehensive results summary\n",
        "    results = {\n",
        "        'phase': 'Phase 4: Model Optimization and Validation',\n",
        "        'optimization_date': datetime.now().isoformat(),\n",
        "        'cross_validation_results': cv_results,\n",
        "        'feature_selection_results': {\n",
        "            'optimal_k': best_k,\n",
        "            'selected_features': best_features,\n",
        "            'performance_by_k': {str(k): {\n",
        "                'val_rmse': feature_selection_results[k]['val_rmse'],\n",
        "                'val_mae': feature_selection_results[k]['val_mae'],\n",
        "                'val_r2': feature_selection_results[k]['val_r2']\n",
        "            } for k in feature_selection_results.keys()}\n",
        "        },\n",
        "        'best_models': {\n",
        "            'xgboost': {\n",
        "                'model_file': 'Models/optimized_xgboost_model.pkl',\n",
        "                'cv_rmse': cv_results.get('XGBoost', {}).get('mean_rmse', 'N/A')\n",
        "            },\n",
        "            'random_forest': {\n",
        "                'model_file': 'Models/optimized_random_forest_model.pkl',\n",
        "                'cv_rmse': cv_results.get('Random Forest', {}).get('mean_rmse', 'N/A')\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Save results\n",
        "    with open('Data/processed/MLE_Improved/phase4_optimization_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    \n",
        "    logging.info(\"Optimization results saved successfully!\")\n",
        "\n",
        "# Save optimization results\n",
        "save_optimization_results(best_xgb, best_rf, cv_results, feature_selection_results, best_k, scaler)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4 Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find best model\n",
        "best_model_name = min(cv_results.keys(), key=lambda x: cv_results[x]['mean_rmse'])\n",
        "best_cv_rmse = cv_results[best_model_name]['mean_rmse']\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 4 OPTIMIZATION COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Best model: {best_model_name}\")\n",
        "print(f\"Best CV RMSE: {best_cv_rmse:.2f} grams\")\n",
        "print(f\"Optimal features: {best_k}\")\n",
        "print(f\"Selected features: {len(feature_selection_results[best_k]['selected_features'])}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
