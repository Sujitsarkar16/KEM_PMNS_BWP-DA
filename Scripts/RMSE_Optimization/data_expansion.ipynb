{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Data Expansion and Variable Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.1: Load and Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_explore_data():\n",
        "    \"\"\"Load the cleaned dataset and explore its structure\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"PHASE 1: DATA EXPANSION AND VARIABLE SELECTION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Load data\n",
        "    data = pd.read_csv('Data/processed/cleaned_dataset_with_engineered_features.csv')\n",
        "    print(f\"Dataset loaded: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
        "    \n",
        "    # Check current MLE results\n",
        "    mle_metrics = pd.read_csv('Data/processed/mle_performance_metrics.csv')\n",
        "    print(f\"\\nCurrent MLE Performance:\")\n",
        "    print(f\"RMSE: {mle_metrics['RMSE'].iloc[0]:.2f} grams\")\n",
        "    print(f\"MAE: {mle_metrics['MAE'].iloc[0]:.2f} grams\")\n",
        "    print(f\"R²: {mle_metrics['R²'].iloc[0]:.4f}\")\n",
        "    print(f\"Sample Size: {mle_metrics['Sample_Size'].iloc[0]}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Load the data\n",
        "data = load_and_explore_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.2: Identify All Available Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def identify_all_variables(data):\n",
        "    \"\"\"Step 1.1: Identify all available variables for birthweight prediction\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 1.1: IDENTIFY ALL AVAILABLE VARIABLES\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Define variable categories based on the implementation plan\n",
        "    variable_categories = {\n",
        "        'MATERNAL_DEMOGRAPHICS': [\n",
        "            'f0_m_age', 'f0_m_edu', 'f0_f_edu', 'f0_occ_hou_head', \n",
        "            'f0_socio_eco_sc', 'f0_caste_fly'\n",
        "        ],\n",
        "        'MATERNAL_ANTHROPOMETRY': [\n",
        "            'f0_m_ht', 'f0_m_wt_prepreg', 'f0_m_bmi_prepreg',\n",
        "            'f0_m_waist_prepreg', 'f0_m_hip_prepreg',\n",
        "            'f0_m_tr_prepreg', 'f0_m_bi_prepreg', 'f0_m_ss_prepreg',\n",
        "            'f0_m_su_prepreg', 'f0_m_ma_prepreg'\n",
        "        ],\n",
        "        'PREGNANCY_HISTORY': [\n",
        "            'f0_m_gravida_v1', 'f0_m_parity_v1', 'f0_m_abor_v1',\n",
        "            'f0_m_liv_male_v1', 'f0_m_liv_female_v1',\n",
        "            'f0_m_still_birth_v1', 'f0_m_neo_death_v1'\n",
        "        ],\n",
        "        'MATERNAL_HEALTH_V1': [\n",
        "            'f0_m_hb_v1', 'f0_m_glu_f_v1', 'f0_m_sys_bp_r1_v1',\n",
        "            'f0_m_dia_bp_r1_v1', 'f0_m_wbc_v1', 'f0_m_rbc_v1',\n",
        "            'f0_m_plt_v1', 'f0_m_hct_v1', 'f0_m_b12_v1', 'f0_m_fer_v1'\n",
        "        ],\n",
        "        'MATERNAL_HEALTH_V2': [\n",
        "            'f0_m_hb_v2', 'f0_m_glu_f_v2', 'f0_m_sys_bp_r1_v2',\n",
        "            'f0_m_dia_bp_r1_v2', 'f0_m_wbc_v2', 'f0_m_rbc_v2',\n",
        "            'f0_m_plt_v2', 'f0_m_hct_v2', 'f0_m_b12_v2', 'f0_m_fer_v2'\n",
        "        ],\n",
        "        'GESTATIONAL_FACTORS': [\n",
        "            'f0_m_GA_V1', 'f0_m_GA_V2', 'f0_m_GA_Del', 'f0_m_plac_wt'\n",
        "        ],\n",
        "        'CHILD_FACTORS': [\n",
        "            'f1_sex', 'f0_m_del_mode'\n",
        "        ],\n",
        "        'NUTRITIONAL_FACTORS': [\n",
        "            'f0_m_totcal_v1', 'f0_m_totcal_v2', 'f0_m_totpro_v1', 'f0_m_totpro_v2',\n",
        "            'f0_m_totfat_v1', 'f0_m_totfat_v2', 'f0_m_totiron_v1', 'f0_m_totiron_v2'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Check which variables exist in the dataset\n",
        "    available_vars = {}\n",
        "    missing_vars = {}\n",
        "    \n",
        "    for category, vars_list in variable_categories.items():\n",
        "        available = []\n",
        "        missing = []\n",
        "        \n",
        "        for var in vars_list:\n",
        "            if var in data.columns:\n",
        "                available.append(var)\n",
        "            else:\n",
        "                missing.append(var)\n",
        "        \n",
        "        available_vars[category] = available\n",
        "        missing_vars[category] = missing\n",
        "    \n",
        "    # Print results\n",
        "    print(\"Variable Availability Check:\")\n",
        "    print(\"-\" * 40)\n",
        "    for category, vars_list in available_vars.items():\n",
        "        print(f\"\\n{category}:\")\n",
        "        print(f\"  Available: {len(vars_list)}/{len(variable_categories[category])}\")\n",
        "        if vars_list:\n",
        "            print(f\"  Variables: {vars_list}\")\n",
        "        if missing_vars[category]:\n",
        "            print(f\"  Missing: {missing_vars[category]}\")\n",
        "    \n",
        "    # Get all available variables\n",
        "    all_available = []\n",
        "    for vars_list in available_vars.values():\n",
        "        all_available.extend(vars_list)\n",
        "    \n",
        "    print(f\"\\nTotal Available Variables: {len(all_available)}\")\n",
        "    print(f\"Target: 20+ variables\")\n",
        "    print(f\"Current MLE used: 4 variables\")\n",
        "    \n",
        "    return available_vars, all_available\n",
        "\n",
        "# Identify all available variables\n",
        "available_vars, all_available = identify_all_variables(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.3: Assess Data Quality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assess_data_quality(data, variables):\n",
        "    \"\"\"Step 1.2: Assess data quality for each variable\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 1.2: DATA QUALITY ASSESSMENT\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    quality_metrics = {}\n",
        "    \n",
        "    for var in variables:\n",
        "        if var in data.columns:\n",
        "            # Basic statistics\n",
        "            total_count = len(data)\n",
        "            non_null_count = data[var].count()\n",
        "            null_count = total_count - non_null_count\n",
        "            missing_pct = (null_count / total_count) * 100\n",
        "            \n",
        "            # Data type\n",
        "            dtype = data[var].dtype\n",
        "            \n",
        "            # For numeric variables\n",
        "            if pd.api.types.is_numeric_dtype(data[var]):\n",
        "                # Outlier detection using IQR\n",
        "                Q1 = data[var].quantile(0.25)\n",
        "                Q3 = data[var].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - 1.5 * IQR\n",
        "                upper_bound = Q3 + 1.5 * IQR\n",
        "                \n",
        "                outliers = data[(data[var] < lower_bound) | (data[var] > upper_bound)]\n",
        "                outlier_pct = (len(outliers) / non_null_count) * 100 if non_null_count > 0 else 0\n",
        "                \n",
        "                # Skewness\n",
        "                skewness = data[var].skew()\n",
        "                \n",
        "                quality_metrics[var] = {\n",
        "                    'missing_pct': missing_pct,\n",
        "                    'outlier_pct': outlier_pct,\n",
        "                    'skewness': abs(skewness),\n",
        "                    'dtype': dtype,\n",
        "                    'mean': data[var].mean(),\n",
        "                    'std': data[var].std(),\n",
        "                    'min': data[var].min(),\n",
        "                    'max': data[var].max()\n",
        "                }\n",
        "            else:\n",
        "                # For categorical variables\n",
        "                unique_count = data[var].nunique()\n",
        "                most_common_pct = (data[var].value_counts().iloc[0] / non_null_count) * 100 if non_null_count > 0 else 0\n",
        "                \n",
        "                quality_metrics[var] = {\n",
        "                    'missing_pct': missing_pct,\n",
        "                    'unique_count': unique_count,\n",
        "                    'most_common_pct': most_common_pct,\n",
        "                    'dtype': dtype\n",
        "                }\n",
        "    \n",
        "    # Create quality summary\n",
        "    quality_df = pd.DataFrame(quality_metrics).T\n",
        "    \n",
        "    # Filter criteria\n",
        "    print(\"\\nData Quality Summary:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Variables with <50% missing data: {len(quality_df[quality_df['missing_pct'] < 50])}\")\n",
        "    print(f\"Variables with <30% missing data: {len(quality_df[quality_df['missing_pct'] < 30])}\")\n",
        "    print(f\"Variables with <10% missing data: {len(quality_df[quality_df['missing_pct'] < 10])}\")\n",
        "    \n",
        "    # Show variables by missing data percentage\n",
        "    print(\"\\nMissing Data Analysis:\")\n",
        "    print(\"-\" * 30)\n",
        "    missing_analysis = quality_df[['missing_pct']].sort_values('missing_pct')\n",
        "    print(missing_analysis.head(20))\n",
        "    \n",
        "    return quality_df\n",
        "\n",
        "# Assess data quality for all available variables\n",
        "quality_df = assess_data_quality(data, all_available)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.4: Select Variables Based on Quality Criteria\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_variables(quality_df, target_missing_threshold=50):\n",
        "    \"\"\"Step 1.3: Select variables based on quality criteria\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 1.3: VARIABLE SELECTION AND FILTERING\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Filter variables based on missing data threshold\n",
        "    selected_vars = quality_df[quality_df['missing_pct'] < target_missing_threshold].index.tolist()\n",
        "    \n",
        "    print(f\"Variables selected (missing < {target_missing_threshold}%): {len(selected_vars)}\")\n",
        "    \n",
        "    # Categorize selected variables\n",
        "    selected_categories = {\n",
        "        'DEMOGRAPHICS': [var for var in selected_vars if var.startswith(('f0_m_age', 'f0_m_edu', 'f0_f_edu', 'f0_socio_eco_sc', 'f0_caste_fly'))],\n",
        "        'ANTHROPOMETRY': [var for var in selected_vars if var.startswith(('f0_m_ht', 'f0_m_wt', 'f0_m_bmi', 'f0_m_waist', 'f0_m_hip', 'f0_m_tr', 'f0_m_bi', 'f0_m_ss'))],\n",
        "        'PREGNANCY_HISTORY': [var for var in selected_vars if var.startswith(('f0_m_gravida', 'f0_m_parity', 'f0_m_abor', 'f0_m_liv', 'f0_m_still', 'f0_m_neo'))],\n",
        "        'HEALTH_MARKERS': [var for var in selected_vars if var.startswith(('f0_m_hb', 'f0_m_glu', 'f0_m_sys_bp', 'f0_m_dia_bp', 'f0_m_wbc', 'f0_m_rbc', 'f0_m_plt', 'f0_m_hct', 'f0_m_b12', 'f0_m_fer'))],\n",
        "        'GESTATIONAL': [var for var in selected_vars if var.startswith(('f0_m_GA', 'f0_m_plac'))],\n",
        "        'CHILD_FACTORS': [var for var in selected_vars if var.startswith(('f1_sex', 'f0_m_del'))],\n",
        "        'NUTRITIONAL': [var for var in selected_vars if var.startswith(('f0_m_totcal', 'f0_m_totpro', 'f0_m_totfat', 'f0_m_totiron'))]\n",
        "    }\n",
        "    \n",
        "    print(\"\\nSelected Variables by Category:\")\n",
        "    print(\"-\" * 40)\n",
        "    for category, vars_list in selected_categories.items():\n",
        "        print(f\"{category}: {len(vars_list)} variables\")\n",
        "        if vars_list:\n",
        "            print(f\"  {vars_list}\")\n",
        "    \n",
        "    # Check correlation with target variable\n",
        "    print(\"\\nCorrelation with Birthweight (f1_bw):\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Load data for correlation analysis\n",
        "    data = pd.read_csv('Data/processed/cleaned_dataset_with_engineered_features.csv')\n",
        "    \n",
        "    correlations = {}\n",
        "    for var in selected_vars:\n",
        "        if var in data.columns and 'f1_bw' in data.columns:\n",
        "            corr = data[var].corr(data['f1_bw'])\n",
        "            if not pd.isna(corr):\n",
        "                correlations[var] = corr\n",
        "    \n",
        "    # Sort by absolute correlation\n",
        "    sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n",
        "    \n",
        "    print(\"Top 20 variables by correlation with birthweight:\")\n",
        "    for var, corr in sorted_correlations[:20]:\n",
        "        print(f\"  {var}: {corr:.4f}\")\n",
        "    \n",
        "    return selected_vars, selected_categories, correlations\n",
        "\n",
        "# Select variables based on quality criteria\n",
        "selected_vars, selected_categories, correlations = select_variables(quality_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.5: Create Data Quality Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_quality_visualizations(quality_df, selected_vars, correlations):\n",
        "    \"\"\"Create visualizations for data quality assessment\"\"\"\n",
        "    print(\"\\nCreating data quality visualizations...\")\n",
        "    \n",
        "    # Set up the plotting style\n",
        "    plt.style.use('default')\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # 1. Missing data distribution\n",
        "    missing_pct = quality_df['missing_pct'].sort_values(ascending=False)\n",
        "    axes[0, 0].bar(range(len(missing_pct)), missing_pct.values)\n",
        "    axes[0, 0].axhline(y=50, color='r', linestyle='--', label='50% threshold')\n",
        "    axes[0, 0].axhline(y=30, color='orange', linestyle='--', label='30% threshold')\n",
        "    axes[0, 0].set_xlabel('Variables')\n",
        "    axes[0, 0].set_ylabel('Missing Data Percentage')\n",
        "    axes[0, 0].set_title('Missing Data Distribution')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Selected vs All variables\n",
        "    selected_count = len(selected_vars)\n",
        "    total_count = len(quality_df)\n",
        "    axes[0, 1].pie([selected_count, total_count - selected_count], \n",
        "                   labels=['Selected', 'Excluded'], \n",
        "                   autopct='%1.1f%%',\n",
        "                   colors=['lightgreen', 'lightcoral'])\n",
        "    axes[0, 1].set_title(f'Variable Selection\\n({selected_count}/{total_count} selected)')\n",
        "    \n",
        "    # 3. Correlation with birthweight\n",
        "    if correlations:\n",
        "        corr_values = list(correlations.values())\n",
        "        corr_vars = list(correlations.keys())\n",
        "        \n",
        "        # Sort by absolute correlation\n",
        "        sorted_pairs = sorted(zip(corr_vars, corr_values), key=lambda x: abs(x[1]), reverse=True)\n",
        "        top_vars = [pair[0] for pair in sorted_pairs[:15]]\n",
        "        top_corrs = [pair[1] for pair in sorted_pairs[:15]]\n",
        "        \n",
        "        axes[1, 0].barh(range(len(top_vars)), top_corrs)\n",
        "        axes[1, 0].set_yticks(range(len(top_vars)))\n",
        "        axes[1, 0].set_yticklabels(top_vars, fontsize=8)\n",
        "        axes[1, 0].set_xlabel('Correlation with Birthweight')\n",
        "        axes[1, 0].set_title('Top 15 Variables by Correlation')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Missing data vs Correlation\n",
        "    if correlations:\n",
        "        missing_corr_data = []\n",
        "        corr_data = []\n",
        "        \n",
        "        for var in selected_vars:\n",
        "            if var in quality_df.index and var in correlations:\n",
        "                missing_corr_data.append(quality_df.loc[var, 'missing_pct'])\n",
        "                corr_data.append(abs(correlations[var]))\n",
        "        \n",
        "        if missing_corr_data and corr_data:\n",
        "            axes[1, 1].scatter(missing_corr_data, corr_data, alpha=0.6)\n",
        "            axes[1, 1].set_xlabel('Missing Data Percentage')\n",
        "            axes[1, 1].set_ylabel('Absolute Correlation with Birthweight')\n",
        "            axes[1, 1].set_title('Missing Data vs Correlation')\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('PLOTS/MLE_Improved/phase1_data_quality_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    print(\"Visualizations saved to PLOTS/MLE_Improved/phase1_data_quality_analysis.png\")\n",
        "\n",
        "# Create visualizations\n",
        "create_quality_visualizations(quality_df, selected_vars, correlations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.6: Save Phase 1 Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_phase1_results(selected_vars, selected_categories, correlations, quality_df):\n",
        "    \"\"\"Save Phase 1 results for next phases\"\"\"\n",
        "    print(\"\\nSaving Phase 1 results...\")\n",
        "    \n",
        "    # Create results directory if it doesn't exist\n",
        "    import os\n",
        "    os.makedirs('Data/processed/MLE_Improved', exist_ok=True)\n",
        "    os.makedirs('PLOTS/MLE_Improved', exist_ok=True)\n",
        "    \n",
        "    # Save selected variables\n",
        "    selected_vars_df = pd.DataFrame({\n",
        "        'variable': selected_vars,\n",
        "        'missing_pct': [quality_df.loc[var, 'missing_pct'] for var in selected_vars],\n",
        "        'correlation_with_bw': [correlations.get(var, 0) for var in selected_vars]\n",
        "    })\n",
        "    selected_vars_df.to_csv('Data/processed/MLE_Improved/phase1_selected_variables.csv', index=False)\n",
        "    \n",
        "    # Save quality metrics\n",
        "    quality_df.to_csv('Data/processed/MLE_Improved/phase1_quality_metrics.csv')\n",
        "    \n",
        "    # Save categories\n",
        "    categories_df = pd.DataFrame([\n",
        "        {'category': cat, 'variables': ', '.join(vars_list), 'count': len(vars_list)}\n",
        "        for cat, vars_list in selected_categories.items()\n",
        "    ])\n",
        "    categories_df.to_csv('Data/processed/MLE_Improved/phase1_variable_categories.csv', index=False)\n",
        "    \n",
        "    # Save summary\n",
        "    summary = {\n",
        "        'phase': 'Phase 1: Data Expansion and Variable Selection',\n",
        "        'total_variables_available': len(quality_df),\n",
        "        'variables_selected': len(selected_vars),\n",
        "        'selection_criteria': 'Missing data < 50%',\n",
        "        'categories': {cat: len(vars_list) for cat, vars_list in selected_categories.items()},\n",
        "        'expected_impact': '20-35% RMSE reduction'\n",
        "    }\n",
        "    \n",
        "    import json\n",
        "    with open('Data/processed/MLE_Improved/phase1_summary.json', 'w') as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    \n",
        "    print(\"Phase 1 results saved successfully!\")\n",
        "    print(f\"Selected {len(selected_vars)} variables for next phases\")\n",
        "\n",
        "# Save Phase 1 results\n",
        "save_phase1_results(selected_vars, selected_categories, correlations, quality_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1 Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 1 Completion Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 1 COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"✅ Identified {len(all_available)} available variables\")\n",
        "print(f\"✅ Selected {len(selected_vars)} high-quality variables\")\n",
        "print(f\"✅ Categorized variables into {len(selected_categories)} groups\")\n",
        "print(f\"✅ Ready for Phase 2: Feature Engineering\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
